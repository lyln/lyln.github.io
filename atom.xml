<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>落影流年</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://www.wiredtiger.org/"/>
  <updated>2021-01-17T13:38:13.745Z</updated>
  <id>http://www.wiredtiger.org/</id>
  
  <author>
    <name>Lyln</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Go环境搭建及Go基础</title>
    <link href="http://www.wiredtiger.org/2021/01/17/2021-01-17-go-env-base/"/>
    <id>http://www.wiredtiger.org/2021/01/17/2021-01-17-go-env-base/</id>
    <published>2021-01-16T16:00:00.000Z</published>
    <updated>2021-01-17T13:38:13.745Z</updated>
    
    <content type="html"><![CDATA[<h4 id="Go开发环境搭建"><a href="#Go开发环境搭建" class="headerlink" title="Go开发环境搭建"></a>Go开发环境搭建</h4><pre class="language-none"><code class="language-none">mac升级go版本https:&#x2F;&#x2F;golang.org&#x2F;dl&#x2F;或者这个地址https:&#x2F;&#x2F;studygolang.com&#x2F;dl下载对应的版本设置环境变量即可export GOROOT&#x3D;~&#x2F;goexport PATH&#x3D;$PATH:$GOROOT&#x2F;binGOROOT表示Go语言的安装目录GOPATH用于指定我们的开发工作区(workspace),是存放源代码、测试文件、库静态文件、可执行文件等GOPATH目录下的每个工作一般分为三个子目录:src,pkg,binmkdir $GOPATH&#x2F;&#123;src,pkg,bin&#125;为啥我mac构建的bin部署到服务器上不能用？交叉编译,是指在一个平台上就能生成可以在另一个平台运行的代码。GOOS的默认值是我们当前的操作系统， 如果windows，linux,注意mac os操作的上的值是darwinGOARCH则表示CPU架构，如386，amd64,arm等举个例子GOOS&#x3D;linux GOARCH&#x3D;amd64 go build main.goGo涉及的主要环境变量就都在这里了。</code></pre><h4 id="解决Go各种失败肝疼问题"><a href="#解决Go各种失败肝疼问题" class="headerlink" title="解决Go各种失败肝疼问题"></a>解决Go各种失败肝疼问题</h4><pre class="language-none"><code class="language-none">Go 1.13 及以上（推荐）$ go env -w GO111MODULE&#x3D;on$ go env -w GOPROXY&#x3D;https:&#x2F;&#x2F;goproxy.cn,direct如果提示冲突unset GOPROXY一把</code></pre><p>参考地址</p><p><a href="https://shockerli.net/post/go-get-golang-org-x-solution/">https://shockerli.net/post/go-get-golang-org-x-solution/</a></p><p><a href="https://github.com/goproxy/goproxy.cn/blob/master/README.zh-CN.md">https://github.com/goproxy/goproxy.cn/blob/master/README.zh-CN.md</a></p><h3 id="go-modules使用"><a href="#go-modules使用" class="headerlink" title="go modules使用"></a>go modules使用</h3><pre class="language-none"><code class="language-none">go mod initgo mod运行前执行go mod tidy即可，这个命令会自动下载依赖的库，也会删除多余的库go help mod 查看常用go.mod文件是记录我们依赖库以及版本号</code></pre><h3 id="govendor使用"><a href="#govendor使用" class="headerlink" title="govendor使用"></a>govendor使用</h3><pre class="language-none"><code class="language-none">go get github.com&#x2F;kardianos&#x2F;govendor用govendor初始化项目并拉取gingovendor initgovendor fetch github.com&#x2F;gin-gonic&#x2F;gin</code></pre><h4 id="VSCode-Go配置"><a href="#VSCode-Go配置" class="headerlink" title="VSCode Go配置"></a>VSCode Go配置</h4><p>settings-extensions-go</p><pre class="language-none"><code class="language-none">&#x2F;&#x2F;golang配置&quot;editor.wordWrap&quot;: &quot;on&quot;,&#x2F;&#x2F; 如果useLanguageServer设为true，那么在编写代码时引入本地没有的package时，会自动下载安装&#x2F;&#x2F; 就是有时候会非常卡，保存go的编码文件时偶尔会卡死。这点你们自己取舍吧&quot;go.useLanguageServer&quot;: false,&quot;editor.minimap.renderCharacters&quot;: false,&quot;editor.minimap.enabled&quot;: false,&quot;terminal.external.osxExec&quot;: &quot;iTerm.app&quot;,&quot;go.docsTool&quot;: &quot;gogetdoc&quot;,&quot;go.testFlags&quot;: [&quot;-v&quot;,&quot;-count&#x3D;1&quot;],&quot;go.buildTags&quot;: &quot;&quot;,&quot;go.buildFlags&quot;: [],&quot;go.lintFlags&quot;: [],&quot;go.vetFlags&quot;: [],&quot;go.coverOnSave&quot;: false,&quot;go.useCodeSnippetsOnFunctionSuggest&quot;: false,&quot;go.formatTool&quot;: &quot;goreturns&quot;,&quot;go.gocodeAutoBuild&quot;: false,&quot;go.goroot&quot;: &quot;填写GOROOT路径&quot;,&quot;go.gopath&quot;: &quot;填写GOPATH路径&quot;,&quot;go.autocompleteUnimportedPackages&quot;: true,&quot;go.formatOnSave&quot;: true,&quot;window.zoomLevel&quot;: 0,&quot;debug.console.fontSize&quot;: 16,&quot;debug.console.lineHeight&quot;: 30,</code></pre><h4 id="Go基础"><a href="#Go基础" class="headerlink" title="Go基础"></a>Go基础</h4><pre class="language-none"><code class="language-none">go指针a :&#x3D; 5fmt.Println(a)var pa *intpa &#x3D; &amp;afmt.Println(pa)fmt.Println(*pa)go常量const message string &#x3D; &quot;go入门&quot;</code></pre><h4 id="Go常用命令"><a href="#Go常用命令" class="headerlink" title="Go常用命令"></a>Go常用命令</h4><pre class="language-none"><code class="language-none">go build 编译所有的包和依赖go clean 清理执行其它命令时产生的一些文件和目录go install 编译并安装指定的代码包及它们的依赖包go run 编译并运行命令源码文件go mod init 初始化一个新模块go mod vendor 把所有依赖拷贝到vendor文件夹中go mod tidy 添加缺失的模块，移除无用的模块</code></pre><h3 id="Go语言解析json数据"><a href="#Go语言解析json数据" class="headerlink" title="Go语言解析json数据"></a>Go语言解析json数据</h3><pre class="language-none"><code class="language-none">package main import (&quot;fmt&quot;&quot;go-simplejson-master&quot;&#x2F;&#x2F;注意导入方式,网上常见的导入&quot;github.com&#x2F;bitly&#x2F;go-simplejson&quot;，&#x2F;&#x2F;应该是修改了文件夹的名字，本人修改名字后，试验成功) func main() &#123;js,err:&#x3D;simplejson.NewJson([]byte(&#96;&#123;&quot;test&quot;:&#123;&quot;array&quot;:[1,2,3],&quot;int&quot;:18,&quot;float&quot;:7.66,&quot;string&quot;:&quot;simplejson&quot;,&quot;bignum&quot;:7617690283790,&quot;bool&quot;:true   &#x2F;&#x2F;这里一定不要加逗号，否则会出错&#125;&#125;&#96;)) if err!&#x3D;nil&#123;panic(&quot;json format error&quot;)&#125;else &#123;        &#x2F;&#x2F;按照键值获取json中的数据arr,_:&#x3D;js.Get(&quot;test&quot;).Get(&quot;array&quot;).Array()i,_:&#x3D;js.Get(&quot;test&quot;).Get(&quot;int&quot;).Int()f,_:&#x3D;js.Get(&quot;test&quot;).Get(&quot;float&quot;).Float64()s:&#x3D;js.Get(&quot;test&quot;).Get(&quot;string&quot;).MustString()fmt.Println(arr,i,f,s) &#125; &#125;</code></pre><h4 id="前端js"><a href="#前端js" class="headerlink" title="前端js"></a>前端js</h4><pre class="language-none"><code class="language-none">属性的关系html中 id   jquery前端中 #获取的是idname name属性用于后端c.PostForm(&quot;source_info&quot;)，浏览器会根据name来设定发送到服务器的requestCSS 中 id、class属性的区别 id  #获取class .获取class可以反复使用而id在一个页面中仅能被使用一次。</code></pre>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h4 id=&quot;Go开发环境搭建&quot;&gt;&lt;a href=&quot;#Go开发环境搭建&quot; class=&quot;headerlink&quot; title=&quot;Go开发环境搭建&quot;&gt;&lt;/a&gt;Go开发环境搭建&lt;/h4&gt;&lt;pre class=&quot;language-none&quot;&gt;&lt;code class=&quot;language-
      
    
    </summary>
    
      <category term="Linux" scheme="http://www.wiredtiger.org/categories/Linux/"/>
    
    
      <category term="Loki" scheme="http://www.wiredtiger.org/tags/Loki/"/>
    
  </entry>
  
  <entry>
    <title>轻量日志系统Loki初试</title>
    <link href="http://www.wiredtiger.org/2020/12/20/2020-12-20-loki-install-manual/"/>
    <id>http://www.wiredtiger.org/2020/12/20/2020-12-20-loki-install-manual/</id>
    <published>2020-12-19T16:00:00.000Z</published>
    <updated>2020-12-23T06:27:03.641Z</updated>
    
    <content type="html"><![CDATA[<h3 id="Loki架构"><a href="#Loki架构" class="headerlink" title="Loki架构"></a>Loki架构</h3><p><img src="https://inshub.oss-cn-beijing.aliyuncs.com/blog/loki.jpg" alt="loki"></p><h3 id="Loki部署"><a href="#Loki部署" class="headerlink" title="Loki部署"></a>Loki部署</h3><pre class="language-none"><code class="language-none">$ curl -O -L &quot;wget https:&#x2F;&#x2F;github.91chifun.workers.dev&#x2F;&#x2F;https:&#x2F;&#x2F;github.com&#x2F;grafana&#x2F;loki&#x2F;releases&#x2F;download&#x2F;v2.0.0&#x2F;loki-linux-amd64.zip&quot;# extract the binary$ unzip &quot;loki-linux-amd64.zip&quot;# make sure it is executable$ chmod a+x &quot;loki-linux-amd64&quot;loki-local-config.ymlauth_enabled: falseserver:  http_listen_port: 3100 # 监听端口ingester:  lifecycler:    address: 0.0.0.0 # 监听地址    ring:      kvstore:        store: inmemory      replication_factor: 1    final_sleep: 0s  chunk_idle_period: 5m  chunk_retain_period: 30s  max_transfer_retries: 0schema_config:  configs:    - from: 2018-04-15      store: boltdb      object_store: filesystem      schema: v11      index:        prefix: index_        period: 144h  #  每张表的时间范围 6天      chunks:        period: 144hstorage_config:#  流文件存储地址  boltdb:    directory: &#x2F;data&#x2F;apps&#x2F;opt&#x2F;loki&#x2F;index#  索引存储地址  filesystem:    directory: &#x2F;data&#x2F;apps&#x2F;opt&#x2F;loki&#x2F;chunkslimits_config:  enforce_metric_name: false  reject_old_samples: true  reject_old_samples_max_age: 144hchunk_store_config:  max_look_back_period: 2160h  # 最大可查询历史日期 90天table_manager:   # 表的保留期90天  retention_deletes_enabled: true  retention_period: 2160hnohup .&#x2F;loki-linux-amd64 -config.file&#x3D;.&#x2F;loki-local-config.yml &gt; loki.log 2&gt;&amp;1 &amp;</code></pre><h3 id="promtail部署"><a href="#promtail部署" class="headerlink" title="promtail部署"></a>promtail部署</h3><pre class="language-none"><code class="language-none">wget https:&#x2F;&#x2F;github.91chifun.workers.dev&#x2F;&#x2F;https:&#x2F;&#x2F;github.com&#x2F;grafana&#x2F;loki&#x2F;releases&#x2F;download&#x2F;v2.0.0&#x2F;promtail-linux-amd64.zipunzip promtail-linux-amd64.zippromtail-local-config.yamlserver:  http_listen_port: 9080  grpc_listen_port: 0  positions:  filename: &#x2F;etc&#x2F;promtail&#x2F;positions.yaml   # 游标记录上一次同步位置  sync_period: 10s #10秒钟同步一次clients:  - url: http:&#x2F;&#x2F;localhost:3100&#x2F;loki&#x2F;api&#x2F;v1&#x2F;push # loki服务地址 scrape_configs:- job_name: system  static_configs:  - targets:      - localhost    labels:      job: nginx-logs # labels名称      __path__: &#x2F;data&#x2F;wwwlogs&#x2F;access.log # 采集日志的路径      启动   nohup .&#x2F;promtail-linux-amd64 -config.file promtail-local-config.yaml &gt; promtai.log 2&gt;&amp;1 &amp;   </code></pre><p><img src="https://inshub.oss-cn-beijing.aliyuncs.com/blog/loki-nginx-log.jpg" alt="loki"></p><h3 id="LogQL语法（Loki）"><a href="#LogQL语法（Loki）" class="headerlink" title="LogQL语法（Loki）"></a>LogQL语法（Loki）</h3><p><strong>日志流选择器</strong>（log stream selector）</p><p>对于查询表达式的标签部分，将其包装在花括号中<code>&#123;&#125;</code></p><ul><li>=等于</li><li>!=不相等</li><li>=~正则表达式匹配</li><li>!~不匹配正则表达式</li></ul><pre class="language-none"><code class="language-none">&#123;job&#x3D;&quot;nginx-error-logs&quot;&#125; </code></pre><p><strong>过滤器表达式</strong>（filter expression）</p><p>编写日志流选择器后，您可以通过编写搜索表达式来进一步过滤结果。</p><pre class="language-none"><code class="language-none">&#123;job&#x3D;&quot;nginx-error-logs&quot;&#125; |&#x3D; &quot;ss.sohu.com&quot;</code></pre><p>已实现以下过滤器类型：</p><ul><li>|= 行包含字符串。</li><li>!= 行不包含字符串。</li><li>|~ 行匹配正则表达式。</li><li>!~ 行与正则表达式不匹配。</li></ul><p><strong>日志度量</strong></p><p>LogQL同样也支持有限的<code>区间向量</code>度量语句，使用方式也和PromQL类似，常用函数主要是如下4个：</p><ul><li>rate: 计算每秒的日志条目</li><li>count_over_time: 对指定范围内的每个日志流的条目进行计数</li><li>bytes_rate: 计算日志流每秒的字节数</li><li>bytes_over_time: 对指定范围内的每个日志流的使用的字节数</li></ul><p><strong>日志统计</strong></p><ul><li><p>rate: calculate the number of entries per second</p><pre class="language-none"><code class="language-none">rate((&#123;job&#x3D;&quot;nginx-error-logs&quot;&#125; |&#x3D; &quot;abc.com&quot;[60s]))</code></pre></li><li><p>Get the count of logs during the last five minutes, grouping by level:</p><pre class="language-none"><code class="language-none">sum(count_over_time(&#123;job&#x3D;&quot;mysql&quot;&#125;[5m])) by (level)</code></pre></li><li><p>Get the top 10 applications by the highest log throughput:</p><pre class="language-none"><code class="language-none">topk(10,sum(rate(&#123;region&#x3D;&quot;us-east1&quot;&#125;[5m])) by (name))</code></pre></li><li><p>Get the rate of HTTP GET requests from NGINX logs:</p><pre class="language-none"><code class="language-none">avg(rate((&#123;job&#x3D;&quot;nginx&quot;&#125; |&#x3D; &quot;GET&quot;)[10s])) by (region)</code></pre></li></ul><p><strong>聚合函数</strong></p><ul><li>sum: Calculate sum over labels</li><li>min: Select minimum over labels</li><li>max: Select maximum over labels</li><li>avg: Calculate the average over labels</li><li>stddev: Calculate the population standard deviation over labels</li><li>stdvar: Calculate the population standard variance over labels</li><li>count: Count number of elements in the vector</li><li>bottomk: Select smallest k elements by sample value</li><li>topk: Select largest k elements by sample value</li></ul><h3 id="问题汇总"><a href="#问题汇总" class="headerlink" title="问题汇总"></a>问题汇总</h3><p>问题描述：</p><pre class="language-none"><code class="language-none">error&#x3D;&quot;server returned HTTP status 429 Too Many Requests (429): Ingestion rate limit exceeded (limit: 4194304 bytes&#x2F;sec) while attempting to ingest &#39;2494&#39; lines totaling &#39;1048456&#39; bytes, reduce log volume or contact your Loki administrator to see if the limit can be increased&quot;</code></pre><p>问题解决：</p><p>修改loki的配置文件,在limits_config中添加</p><pre class="language-none"><code class="language-none">limits_config:  enforce_metric_name: false  reject_old_samples: true  reject_old_samples_max_age: 168h  ingestion_rate_mb: 15 # 增加配置</code></pre><h3 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h3><p><a href="https://lian.st/4114.html">https://lian.st/4114.html</a></p><p><a href="https://happywzy.top/ri-zhi-ju-he-gong-ju-loki-shi-yong-logql/">https://happywzy.top/ri-zhi-ju-he-gong-ju-loki-shi-yong-logql/</a></p><p><a href="https://github.com/grafana/loki/blob/v1.5.0/docs/logql.md">https://github.com/grafana/loki/blob/v1.5.0/docs/logql.md</a></p><p><a href="https://grafana.com/docs/loki/latest/clients/promtail/pipelines/">https://grafana.com/docs/loki/latest/clients/promtail/pipelines/</a></p><p><a href="https://promcon.io/2019-munich/slides/lt1-08_logql-in-5-minutes.pdf">https://promcon.io/2019-munich/slides/lt1-08_logql-in-5-minutes.pdf</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;Loki架构&quot;&gt;&lt;a href=&quot;#Loki架构&quot; class=&quot;headerlink&quot; title=&quot;Loki架构&quot;&gt;&lt;/a&gt;Loki架构&lt;/h3&gt;&lt;p&gt;&lt;img src=&quot;https://inshub.oss-cn-beijing.aliyuncs.com/b
      
    
    </summary>
    
      <category term="Linux" scheme="http://www.wiredtiger.org/categories/Linux/"/>
    
    
      <category term="Loki" scheme="http://www.wiredtiger.org/tags/Loki/"/>
    
  </entry>
  
  <entry>
    <title>etcd部署及数据迁移</title>
    <link href="http://www.wiredtiger.org/2020/11/21/2020-11-21-etcd-migrate-date-md/"/>
    <id>http://www.wiredtiger.org/2020/11/21/2020-11-21-etcd-migrate-date-md/</id>
    <published>2020-11-20T16:00:00.000Z</published>
    <updated>2020-11-20T10:41:21.960Z</updated>
    
    <content type="html"><![CDATA[<h3 id="环境概况"><a href="#环境概况" class="headerlink" title="环境概况"></a>环境概况</h3><pre class="language-none"><code class="language-none">etcdctl version 2.3.7</code></pre><p>最近迁移没人维护的老项目，涉及etcd2 服务的迁移，项目代码没人维护，所以只能平迁到etcd2版本。本来很简单的问题，结果快被整崩溃了。<br>遂记录下迁移过程。</p><p>问题：<br><pre class="language-none"><code class="language-none">etcd[7663]: request cluster ID mismatch (got 75dea77f7702 want bfa24343767ba2e5)</code></pre><br>迁移顺序不对就如上错误。</p><p><img src="https://inshub.oss-cn-beijing.aliyuncs.com/blog/etcd_error.jpg" alt="etcd_error"></p><h3 id="部署etcd"><a href="#部署etcd" class="headerlink" title="部署etcd"></a>部署etcd</h3><p>部署使用原来k8s 安装etcd服务的ansible脚本，直接部署成功。<br>下面操作需要注意顺序～～～<br>停止集群所有节点etcd服务，清空data-dir目录数据待用。</p><h3 id="备份旧版本数据"><a href="#备份旧版本数据" class="headerlink" title="备份旧版本数据"></a>备份旧版本数据</h3><pre class="language-none"><code class="language-none">.&#x2F;etcdctl backup --data-dir &#x2F;data&#x2F;apps&#x2F;data&#x2F;etcd -backup-dir &#x2F;tmp&#x2F;etcd_backup</code></pre><p>备份成功的数据同步到新部署集群的etcd1节点data-dir数据目录</p><p>使用 -–force-new-cluster 参数启动Etcd服务。这个参数会重置集群ID和集群的所有成员信息。<br><pre class="language-none"><code class="language-none"># -initial-clusterINITIAL_CLUSTER&#x3D;&#39;-initial-cluster etcd1&#x3D;http:&#x2F;&#x2F;192.168.1.101:2380&#39;# -initial-cluster-stateINITIAL_CLUSTER_STATE&#x3D;&#39;-initial-cluster-state existing&#39;# -data-dirDATA_DIR&#x3D;&#39;-data-dir &#x2F;data&#x2F;apps&#x2F;data&#x2F;etcd&#39;# other parametersETCD_OPTS&#x3D;&#39;--force-new-cluster&#x3D;&#39;true&#39;&#39;#ETCD_OPTS&#x3D;&#39;&#39;</code></pre></p><p>由于etcdctl不具备修改成员节点参数的功能，使用API操作要来完成。<br><pre class="language-none"><code class="language-none">.&#x2F;bin&#x2F;etcdctl --endpoints http:&#x2F;&#x2F;localhost:2379 member listcurl http:&#x2F;&#x2F;127.0.0.1:2379&#x2F;v2&#x2F;members&#x2F;xxx_id -XPUT \ -H &quot;Content-Type:application&#x2F;json&quot; -d &#39;&#123;&quot;peerURLs&quot;:[&quot;http:&#x2F;&#x2F;192.168.1.101:2380&quot;]&#125;&#39;</code></pre><br>启动etcd1节点。</p><h3 id="etcd添加节点"><a href="#etcd添加节点" class="headerlink" title="etcd添加节点"></a>etcd添加节点</h3><p>etcd添加新节点顺序，首先添加etcd2节点到集群，然后再重启服务。<br><pre class="language-none"><code class="language-none">etcd1执行，添加新节点操作.&#x2F;bin&#x2F;etcdctl --endpoints http:&#x2F;&#x2F;localhost:2379 member add etcd2 http:&#x2F;&#x2F;192.168.1.102:2380</code></pre></p><p>修改etcd2配置<br><pre class="language-none"><code class="language-none"># -initial-clusterINITIAL_CLUSTER&#x3D;&#39;-initial-cluster etcd1&#x3D;192.168.1.101:2380,etcd2&#x3D;http:&#x2F;&#x2F;192.168.1.102:2380&#39;# -initial-cluster-stateINITIAL_CLUSTER_STATE&#x3D;&#39;-initial-cluster-state existing&#39;</code></pre><br>etcd2启动成功，etcd3同上，区别完善下INITIAL_CLUSTER 节点列表。</p><p>将各节点etcd.conf配置文件的变量ETCD_INITIAL_CLUSTER添加新节点信息，然后依次重启。</p><h3 id="常用命令"><a href="#常用命令" class="headerlink" title="常用命令"></a>常用命令</h3><pre class="language-none"><code class="language-none">.&#x2F;bin&#x2F;etcdctl --endpoints http:&#x2F;&#x2F;localhost:2379 cluster-health.&#x2F;bin&#x2F;etcdctl --endpoints http:&#x2F;&#x2F;localhost:2379 member list.&#x2F;bin&#x2F;etcdctl --endpoints http:&#x2F;&#x2F;localhost:2379 member add etcd2 http:&#x2F;&#x2F;192.168.1.102:2380.&#x2F;bin&#x2F;etcdctl --endpoints http:&#x2F;&#x2F;localhost:2379 member remove cluster_id</code></pre><p>参考地址：<br><a href="https://jusene.github.io/2017/11/12/etcd-cluster/">https://jusene.github.io/2017/11/12/etcd-cluster/</a><br><a href="https://www.cnblogs.com/ilifeilong/p/11625151.html">https://www.cnblogs.com/ilifeilong/p/11625151.html</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;环境概况&quot;&gt;&lt;a href=&quot;#环境概况&quot; class=&quot;headerlink&quot; title=&quot;环境概况&quot;&gt;&lt;/a&gt;环境概况&lt;/h3&gt;&lt;pre class=&quot;language-none&quot;&gt;&lt;code class=&quot;language-none&quot;&gt;etcdctl ve
      
    
    </summary>
    
      <category term="Linux" scheme="http://www.wiredtiger.org/categories/Linux/"/>
    
    
      <category term="etcd" scheme="http://www.wiredtiger.org/tags/etcd/"/>
    
  </entry>
  
  <entry>
    <title>Docker快速构建测试环境</title>
    <link href="http://www.wiredtiger.org/2020/10/21/2020-10-21-docker-install-develop/"/>
    <id>http://www.wiredtiger.org/2020/10/21/2020-10-21-docker-install-develop/</id>
    <published>2020-10-20T16:00:00.000Z</published>
    <updated>2020-12-29T03:26:04.972Z</updated>
    
    <content type="html"><![CDATA[<p><strong>快速构建各种开发测试环境汇总</strong></p><h4 id="MySQL5-7开发环境"><a href="#MySQL5-7开发环境" class="headerlink" title="MySQL5.7开发环境"></a>MySQL5.7开发环境</h4><pre class="language-shell" data-language="shell"><code class="language-shell">docker run --name<span class="token operator">=</span>my-db -p3306:3306 -d mysql/mysql-server:5.7获取临时密码docker logs mysql1 <span class="token operator"><span class="token file-descriptor important">2</span>></span><span class="token file-descriptor important">&amp;1</span> <span class="token operator">|</span> <span class="token function">grep</span> GENERATEDGENERATED ROOT PASSWORD: Axegh3kAJyDLaRuBemecis<span class="token operator">&amp;</span>EShOsdocker <span class="token builtin class-name">exec</span> -it my-db mysql -uroot -p<span class="token operator">></span> ALTER <span class="token environment constant">USER</span> <span class="token string">'root'</span>@<span class="token string">'localhost'</span> IDENTIFIED BY <span class="token string">'password'</span><span class="token punctuation">;</span><span class="token operator">></span> create user admin@<span class="token string">'%'</span> identified by <span class="token string">'admin123'</span><span class="token punctuation">;</span><span class="token operator">></span> grant all privileges on *.* to admin@'%’<span class="token punctuation">;</span>查看创建用户<span class="token operator">></span> <span class="token keyword">select</span> user,host,authentication_string from mysql.user<span class="token punctuation">;</span></code></pre><p>参考地址：</p><p><a href="https://hub.docker.com/r/mysql/mysql-server/">https://hub.docker.com/r/mysql/mysql-server/</a></p><h4 id="Redis开发环境"><a href="#Redis开发环境" class="headerlink" title="Redis开发环境"></a>Redis开发环境</h4><pre class="language-shell" data-language="shell"><code class="language-shell">docker run --name my-redis -p6379:6379 -d redis</code></pre><p>参考地址：</p><p><a href="https://hub.docker.com/_/redis">https://hub.docker.com/_/redis</a></p><h4 id="Nacos开发环境"><a href="#Nacos开发环境" class="headerlink" title="Nacos开发环境"></a>Nacos开发环境</h4><pre class="language-shell" data-language="shell"><code class="language-shell">docker run -e <span class="token assign-left variable">MODE</span><span class="token operator">=</span>standalone -e <span class="token assign-left variable">PREFER_HOST_MODE</span><span class="token operator">=</span>hostname --name my-nacos -p <span class="token number">8848</span>:8848 -d nacos/nacos-server:1.2.1</code></pre><p>参考地址：</p><p><a href="https://github.com/nacos-group/nacos-docker">https://github.com/nacos-group/nacos-docker</a></p><h4 id="Nginx开发环境"><a href="#Nginx开发环境" class="headerlink" title="Nginx开发环境"></a>Nginx开发环境</h4><pre class="language-none"><code class="language-none">docker run --name my-nginx -d -p 9090:80 nginxnginx映射配置&#x2F;etc&#x2F;nginx&#x2F;conf.ddocker run --name my-nginx -v &#x2F;root&#x2F;confd_nginx:&#x2F;etc&#x2F;nginx&#x2F;conf.d -d -p 9090:80 nginx</code></pre><p>参考地址：</p><p><a href="https://hub.docker.com/_/nginx">https://hub.docker.com/_/nginx</a></p><h4 id="Grafana开发环境"><a href="#Grafana开发环境" class="headerlink" title="Grafana开发环境"></a>Grafana开发环境</h4><pre class="language-shell" data-language="shell"><code class="language-shell">docker run -d --name<span class="token operator">=</span>my-grafana -p <span class="token number">7000</span>:3000 grafana/grafana:7.3.4</code></pre><p>参考地址：</p><p><a href="https://hub.docker.com/r/grafana/grafana">https://hub.docker.com/r/grafana/grafana</a></p><h3 id="Prometheus开发环境"><a href="#Prometheus开发环境" class="headerlink" title="Prometheus开发环境"></a>Prometheus开发环境</h3><pre class="language-none"><code class="language-none">bind-mount the directory containing prometheus.yml onto &#x2F;etc&#x2F;prometheus by running:docker run -d --name&#x3D;my-prometheus \    -p 9090:9090 \    -v &#x2F;data&#x2F;apps&#x2F;opt&#x2F;prometheus:&#x2F;etc&#x2F;prometheus \    prom&#x2F;prometheus</code></pre><p>参考地址：</p><p><a href="https://prometheus.io/docs/prometheus/latest/installation/">https://prometheus.io/docs/prometheus/latest/installation/</a></p><h3 id="MinIO-对象存储服务"><a href="#MinIO-对象存储服务" class="headerlink" title="MinIO 对象存储服务"></a>MinIO 对象存储服务</h3><p>MinIO 是一个基于Apache License v2.0开源协议的对象存储服务。它兼容亚马逊S3云存储服务接口，非常适合于存储大容量非结构化的数据，例如图片、视频、日志文件、备份数据和容器/虚拟机镜像等，而一个对象文件可以是任意大小，从几kb到最大5T不等。</p><p>MinIO是一个非常轻量的服务,可以很简单的和其他应用的结合，类似 NodeJS, Redis 或者 MySQL。</p><pre class="language-none"><code class="language-none">docker run --name&#x3D;my-minio -d -p 9000:9000 \  -e &quot;MINIO_ACCESS_KEY&#x3D;admin&quot; \  -e &quot;MINIO_SECRET_KEY&#x3D;admin123&quot; \  -v &#x2F;data&#x2F;apps&#x2F;data&#x2F;:&#x2F;data \  minio&#x2F;minio server &#x2F;data </code></pre><p>参考地址：</p><p><a href="https://docs.min.io/cn/minio-quickstart-guide.html">https://docs.min.io/cn/minio-quickstart-guide.html</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;strong&gt;快速构建各种开发测试环境汇总&lt;/strong&gt;&lt;/p&gt;
&lt;h4 id=&quot;MySQL5-7开发环境&quot;&gt;&lt;a href=&quot;#MySQL5-7开发环境&quot; class=&quot;headerlink&quot; title=&quot;MySQL5.7开发环境&quot;&gt;&lt;/a&gt;MySQL5.7开发环
      
    
    </summary>
    
      <category term="Docker" scheme="http://www.wiredtiger.org/categories/Docker/"/>
    
    
      <category term="docker mysql redis" scheme="http://www.wiredtiger.org/tags/docker-mysql-redis/"/>
    
  </entry>
  
  <entry>
    <title>KubeSphere3.0踩坑指南</title>
    <link href="http://www.wiredtiger.org/2020/09/10/2020-09-10-k8s-install-kubesphere3.0/"/>
    <id>http://www.wiredtiger.org/2020/09/10/2020-09-10-k8s-install-kubesphere3.0/</id>
    <published>2020-09-09T16:00:00.000Z</published>
    <updated>2020-11-20T10:45:28.508Z</updated>
    
    <content type="html"><![CDATA[<h3 id="环境概况"><a href="#环境概况" class="headerlink" title="环境概况"></a>环境概况</h3><pre class="language-none"><code class="language-none">ansible脚本部署k8s集群k8s版本v1.17.11helm版本v3.2.1默认的 storageclass</code></pre><h3 id="部署准备"><a href="#部署准备" class="headerlink" title="部署准备"></a>部署准备</h3><p>helm3安装<br><pre class="language-none"><code class="language-none">下载[helm3](https:&#x2F;&#x2F;get.helm.sh&#x2F;helm-v3.4.0-linux-amd64.tar.gz)tar -zxvf helm-v3.4.0-linux-amd64.tar.gzmv linux-amd64&#x2F;helm &#x2F;usr&#x2F;local&#x2F;bin&#x2F;helm查看helm源helm repo listhelm repo add stable http:&#x2F;&#x2F;mirror.azure.cn&#x2F;kubernetes&#x2F;chartshelm repo add incubator http:&#x2F;&#x2F;mirror.azure.cn&#x2F;kubernetes&#x2F;charts-incubatorhelm inspect values harbor&#x2F;harbor &gt; values.yamlhelm install harbor harbor&#x2F;harbor -f values.yamlhelm uninstall harbor</code></pre><br><a id="more"></a></p><p>nfs文件共享<br><pre class="language-none"><code class="language-none">yum install nfs-utilscat &#x2F;etc&#x2F;exports&#x2F;data&#x2F;apps&#x2F;data&#x2F; *(rw,sync,no_root_squash)#配置生效exportfs -r#查看生效exportfsshowmount  -eservice nfs start</code></pre></p><h3 id="部署nfs默认存储"><a href="#部署nfs默认存储" class="headerlink" title="部署nfs默认存储"></a>部署nfs默认存储</h3><pre class="language-none"><code class="language-none">helm install my-nfs-provisioner --set nfs.server&#x3D;192.168.10.116 --set nfs.path&#x3D;&#x2F;data&#x2F;apps&#x2F;data stable&#x2F;nfs-client-provisioner -n kube-system改变默认 StorageClasskubectl patch storageclass nfs-client -p &#39;&#123;&quot;metadata&quot;: &#123;&quot;annotations&quot;:&#123;&quot;storageclass.kubernetes.io&#x2F;is-default-class&quot;:&quot;true&quot;&#125;&#125;&#125;&#39;</code></pre><h3 id="kubesphere3-0安装"><a href="#kubesphere3-0安装" class="headerlink" title="kubesphere3.0安装"></a>kubesphere3.0安装</h3><pre class="language-none"><code class="language-none">kubesphere-installer.yaml 安装3.0cluster-configuration.yaml 3.0组件配置文件kubesphere-delete.sh 删除卸载3.0&#x2F;data&#x2F;apps&#x2F;opt&#x2F;kubespherekubectl apply -f kubesphere-installer.yamlkubectl apply -f cluster-configuration.yaml重启安装ks-installerkubectl rollout restart deploy -n kubesphere-system ks-installer重新安装servicemesh重新安装把status里servicemesh的status删掉，然后重启下ks-installerkubectl edit cc -n kubesphere-system ks-installer</code></pre><p>查看所有pod正常运行后<br><img src="https://inshub.oss-cn-beijing.aliyuncs.com/blog/kubesphere-login.png" alt="kubesphere-login"><br>默认用户/密码</p><pre class="language-none"><code class="language-none">admin&#x2F;P@88w0rd</code></pre><p><img src="https://inshub.oss-cn-beijing.aliyuncs.com/blog/kubesphere3.0.png" alt="kubesphere3.0"></p><h3 id="强制删除"><a href="#强制删除" class="headerlink" title="强制删除"></a>强制删除</h3><pre class="language-none"><code class="language-none">强制删除namespaceskubectl  get ns kubesphere-system  -o json &gt; tmp.jsonkubectl proxy curl -k -H &quot;Content-Type:application&#x2F;json&quot; -X PUT --data-binary @tmp.json http:&#x2F;&#x2F;127.0.0.1:8001&#x2F;api&#x2F;v1&#x2F;namespaces&#x2F;kubesphere-monitoring-system&#x2F;finalizekubectl get ns kubernetes-dashboard -o json | jq &#39;.spec.finalizers&#x3D;[]&#39; | curl -X PUT http:&#x2F;&#x2F;localhost:8001&#x2F;api&#x2F;v1&#x2F;namespaces&#x2F;kube-node-lease&#x2F;finalize -H &quot;Content-Type: application&#x2F;json&quot; --data @-kubectl get namespace &quot;kube-node-lease&quot; -o json   | tr -d &quot;\n&quot; | sed &quot;s&#x2F;\&quot;finalizers\&quot;: \[[^]]\+\]&#x2F;\&quot;finalizers\&quot;: []&#x2F;&quot;   | kubectl replace --raw &#x2F;api&#x2F;v1&#x2F;namespaces&#x2F;kube-node-lease&#x2F;finalize -f -pv&#x2F;pvc强制删除kubectl patch pvc opspvc  -p &#39;&#123;&quot;metadata&quot;:&#123;&quot;finalizers&quot;:null&#125;&#125;&#39; -n kube-opskubectl patch pvc -n  kubesphere-monitoring-system prometheus-k8s-db-prometheus-k8s-0  -p &#39;&#123;&quot;metadata&quot;:&#123;&quot;finalizers&quot;:null&#125;&#125;&#39;强制删除crdskubectl get apiserviceskubectl get fluentbits.logging.kubesphere.io -n kubesphere-logging-system fluent-bit -o yaml &gt; b.yaml修改finalizers: nullkubectl apply -f b.yaml 即可强制删除。</code></pre><h3 id="helm安装gitlab"><a href="#helm安装gitlab" class="headerlink" title="helm安装gitlab"></a>helm安装gitlab</h3><pre class="language-none"><code class="language-none">helm pull gitlabhelm install gitlab gitlab-ce&#x2F; -f values.yamlkubectl apply -f my-gitlab-com.yaml卸载gitlabhelm delete gitlab</code></pre><h3 id="安装harbor"><a href="#安装harbor" class="headerlink" title="安装harbor"></a>安装harbor</h3><p>harbor安装使用docker-compose方式</p><p>docker添加私仓地址<br><pre class="language-none"><code class="language-none">DOCKER_OPTS&#x3D;&quot;--log-level&#x3D;warn --storage-driver&#x3D;overlay2 --userland-proxy&#x3D;false --log-opt max-size&#x3D;1g --log-opt max-file&#x3D;5 --insecure-registry&#x3D;my.harbor.io&quot;</code></pre></p><h3 id="source-to-images"><a href="#source-to-images" class="headerlink" title="source to images"></a>source to images</h3><p>测试从gitlab代码库构建镜像</p><p>目的镜像地址<br><pre class="language-none"><code class="language-none">my.harbor.io&#x2F;s2i&#x2F;s2i-test</code></pre></p><p>参考地址：<a href="https://v2-1.docs.kubesphere.io/docs/zh-CN/quick-start/source-to-image/">https://v2-1.docs.kubesphere.io/docs/zh-CN/quick-start/source-to-image/</a></p><h3 id="构建流水线"><a href="#构建流水线" class="headerlink" title="构建流水线"></a>构建流水线</h3><p>kubesphere测试使用流水线构建流程<br>参考地址: <a href="https://v2-1.docs.kubesphere.io/docs/zh-CN/quick-start/devops-online/">https://v2-1.docs.kubesphere.io/docs/zh-CN/quick-start/devops-online/</a></p><p><img src="https://inshub.oss-cn-beijing.aliyuncs.com/blog/devops-online.jpg" alt="devops-online"></p><h3 id="目前问题"><a href="#目前问题" class="headerlink" title="目前问题"></a>目前问题</h3><p>服务治理，流量数据展示有问题，还没有解决。<br>istio版本是1.4.8，其他同学说是可以，可以一起探讨下。</p>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;环境概况&quot;&gt;&lt;a href=&quot;#环境概况&quot; class=&quot;headerlink&quot; title=&quot;环境概况&quot;&gt;&lt;/a&gt;环境概况&lt;/h3&gt;&lt;pre class=&quot;language-none&quot;&gt;&lt;code class=&quot;language-none&quot;&gt;ansible脚本部署k8s集群
k8s版本v1.17.11
helm版本v3.2.1
默认的 storageclass
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&quot;部署准备&quot;&gt;&lt;a href=&quot;#部署准备&quot; class=&quot;headerlink&quot; title=&quot;部署准备&quot;&gt;&lt;/a&gt;部署准备&lt;/h3&gt;&lt;p&gt;helm3安装&lt;br&gt;&lt;pre class=&quot;language-none&quot;&gt;&lt;code class=&quot;language-none&quot;&gt;下载[helm3](https:&amp;#x2F;&amp;#x2F;get.helm.sh&amp;#x2F;helm-v3.4.0-linux-amd64.tar.gz)
tar -zxvf helm-v3.4.0-linux-amd64.tar.gz
mv linux-amd64&amp;#x2F;helm &amp;#x2F;usr&amp;#x2F;local&amp;#x2F;bin&amp;#x2F;helm

查看helm源
helm repo list
helm repo add stable http:&amp;#x2F;&amp;#x2F;mirror.azure.cn&amp;#x2F;kubernetes&amp;#x2F;charts
helm repo add incubator http:&amp;#x2F;&amp;#x2F;mirror.azure.cn&amp;#x2F;kubernetes&amp;#x2F;charts-incubator


helm inspect values harbor&amp;#x2F;harbor &amp;gt; values.yaml

helm install harbor harbor&amp;#x2F;harbor -f values.yaml

helm uninstall harbor&lt;/code&gt;&lt;/pre&gt;&lt;br&gt;
    
    </summary>
    
      <category term="K8S" scheme="http://www.wiredtiger.org/categories/K8S/"/>
    
    
      <category term="kubesphere" scheme="http://www.wiredtiger.org/tags/kubesphere/"/>
    
  </entry>
  
  <entry>
    <title>天津海河英才落户指南及注意事项</title>
    <link href="http://www.wiredtiger.org/2020/05/10/2020-05-10-tianjinluohu-guide/"/>
    <id>http://www.wiredtiger.org/2020/05/10/2020-05-10-tianjinluohu-guide/</id>
    <published>2020-05-09T16:00:00.000Z</published>
    <updated>2020-11-07T09:54:05.814Z</updated>
    
    <content type="html"><![CDATA[<p>落户群聊天记录词云展示<br><img src="https://pic3.zhimg.com/80/v2-cb6d7af83845a67bfd679b9f03782f86_720w.jpg" alt="天津落户沟通交流群词云"></p><p>从新系统（6月8号起）上线到现在（2020年8月10号），已经有不少同学拿到准迁，根据群友反馈的不同时间点，小结一下最近的情况。</p><p>新系统从线上申请到拿到准迁证，大概就2个月左右，其实我感觉速度还不错。只是有些环节可能等待的有些长。</p><p><img src="https://pic4.zhimg.com/80/v2-567a25fd3b079a85c81e6a076d0aecc3_720w.jpg" alt="落户过程时间点"></p><a id="more"></a><p>在疫情期间，海河计划网上办理不见面，全程线上邮寄办理，不用去一次天津。</p><p>当时听说可能会查异地社保，好多人推荐找中介，自己想反正全程线上，先自己试一试，实在不行再中介。一定要先自己弄，因为多数靠忽悠。</p><p>从申请到拿到准迁证，整个过程还是很顺利的。</p><p>本人记录下详细的操作过程，有些需要的细节，可能帮你躲避一下坑，希望能帮助更多想要或者计划落户的人。</p><p>落户主体流程：<br><pre class="language-none"><code class="language-none">1.天津公安app申报人才落户2.准备所需的资料邮件获取商调函3.用商调函从档案所在地调取档案4.天津收到档案后下准迁证5.拿到准迁去户籍所在地办理迁出6.邮寄迁出资料到天津海河人才，拿到户籍页7.借户口页换取身份证</code></pre><br>总共7步大体流程，下面详细记录下过程。</p><h3 id="天津公安app申报人才落户"><a href="#天津公安app申报人才落户" class="headerlink" title="天津公安app申报人才落户"></a>天津公安app申报人才落户</h3><p><code>【天津公安】APP，依次【引进人才落户】-【用户注册】-【信息填写】-【选择区域】</code></p><p>需要注意2点：</p><ul><li>区域的选择，因为各个区查社保的程度不同，时松时紧。</li><li>信息能写无尽量写无</li></ul><p>申报完成过几分钟就能收到审核通过的短信。</p><p><strong>区域选择很重要，区域选择很重要，区域选择很重要，重要的事情说三遍，不清楚的可以私信我。</strong></p><p>实际操作记录：</p><p>3月11日 天津公安app提交申请<br><img src="https://pic3.zhimg.com/80/v2-170b4695cb1d0f6227835762c1455142_720w.jpg" alt="提交申请"></p><p>短信内容如下：<br><code>【天津公安民生服务】您提交的引进人才落户业务，已通过公安机关户籍审核。请您于90日内，到天津市河西区行政服务中心（地址：天津市河西区洞庭路20号，电话：59586020/59586021）引进人才联审窗口办理材料申报、档案接转等手续。您需要携带以下材料【身份证、学历证、学位证原件及复印件，教育部学历证书电子注册备案表（或学历认证报告原件及复印件）、学位证书查询结果打印件（或学位认证报告原件及复印件）。如果您以劳务派遣的方式在天津注册企业工作，除提供上述相关材料之外，还需提供在津社保缴费凭证原件及复印件。】</code></p><h3 id="准备所需的资料邮件获取商调函"><a href="#准备所需的资料邮件获取商调函" class="headerlink" title="准备所需的资料邮件获取商调函"></a>准备所需的资料邮件获取商调函</h3><p>申报通过后，准备所需要的资料，邮寄获取商调函。<br>具体需要资料参见 新落户人员细则.doc 附件。</p><p>基本所需资料整理罗列下：</p><ul><li style="list-style: none"><input type="checkbox"></input> 1、身份证（正反面）</li><li style="list-style: none"><input type="checkbox"></input> 2、学历证</li><li style="list-style: none"><input type="checkbox"></input> 3、学位证</li><li style="list-style: none"><input type="checkbox"></input> 4、学历认证报告</li><li style="list-style: none"><input type="checkbox"></input> 5、学位认证报告</li><li style="list-style: none"><input type="checkbox"></input> 6、学位证书查询结果打印件</li><li style="list-style: none"><input type="checkbox"></input> 7、个人落户承诺书</li><li style="list-style: none"><input type="checkbox"></input> 8、手持身份证照片</li><li style="list-style: none"><input type="checkbox"></input> 9、手持个人承诺书照片</li></ul><p>以上资料均提供复印件<br>准备学历及学位的网站地址，获取电子版并打印<br><a href="https://my.chsi.com.cn/archive/index.jsp">https://my.chsi.com.cn/archive/index.jsp</a></p><p>实际操作记录：<br>准备好资料邮寄基本下一个星期就可以处理。<br><code>邮寄地址：地址：天津市河西区澧水道14号，电话：022-59586021  59586020在邮件封面明显位置写明“海河英才”字样。</code><br><strong>3月23日 补了下资料，收到审核通过，确认商调函获取方式</strong><br>审核通过后会收到如下短信<br><code>【天津公安民生服务】您提交的编号xxxx的业务引进人才落户，状态为已经通过线下审核。请您到“天津公安”APP或“天津公安民生服务平台”微信公众号中的【人才引进落户申请-业务办理进度查询】确认《委托存档商调函》的获取方式。</code></p><h3 id="用商调函从档案所在地调取档案"><a href="#用商调函从档案所在地调取档案" class="headerlink" title="用商调函从档案所在地调取档案"></a>用商调函从档案所在地调取档案</h3><p>上一步确认商调函获取方式其实只要选择邮寄就行，过三天后，会有专门的ems人微信联系你填写调档函的邮寄地址。<br>这个邮件地址是你档案所在地址，你可以委托家人去调档。</p><p>实际操作记录：<br><strong>3月26日 海河收到ems电话 填写收件人地址，发送。</strong></p><p>家人收到调档函去人才调取档案，我家里选择的机要方式。机要方式相对较慢，大概半月左右。</p><p>实际操作记录：<br>4月1日 档案机要邮寄</p><p>机要查询地址<br><a href="http://hhycjh.tjrc.com.cn/jyyz.jsp">http://hhycjh.tjrc.com.cn/jyyz.jsp</a></p><p>4月16日天津收到档案。<br><code>通过行政服务中心取得商调函并办理档案调转的英才请注意： 1、存档编号以WT开头的为问题档案，请注意接听北方人才的电话反馈，或主动电话联系北方人才咨询相关问题，联系方式022-24237206。 2、存档编号以HHYC开头的为正式存档，您可凭行政服务中心的短信通知或直接到之前办理联审的行政服务中心申领《准予迁入证明》。 温馨提示：其他形式存档和落户人员获取《准予迁入证明》的方式请详询其所对应的申报机构。</code></p><p>4月21日 档案问题处理</p><p>4月22日 收到已存档<br><code>【天津公安民生服务】您提交的编号xxx的业务引进人才落户，状态为档案已存档。请您到“天津公安”APP或“天津公安民生服务平台”微信公众号中的【人才引进落户申请-业务办理进度查询】确认《准予迁入证明》的获取方式。</code></p><h3 id="天津收到档案后下准迁证"><a href="#天津收到档案后下准迁证" class="headerlink" title="天津收到档案后下准迁证"></a>天津收到档案后下准迁证</h3><p>查询档案存档后，就可以拿到准迁证。你收到准迁的短信后，还是原来的ems人员会联系你将你准迁邮件到那里。这个有ems人微信联系你填写邮寄地址。</p><p><strong>5月1日拿到准迁证。</strong></p><p>拿到准迁基本就没啥问题了，如果你找中介，也是拿到准迁后再给钱。记住，不然你可能会被社会毒打教训，后悔莫及。</p><h3 id="拿到准迁去户籍所在地办理迁出"><a href="#拿到准迁去户籍所在地办理迁出" class="headerlink" title="拿到准迁去户籍所在地办理迁出"></a>拿到准迁去户籍所在地办理迁出</h3><p>五一放假回家刚好去户籍派出所办理下迁出，办理迁出，拿着准迁及原来的户籍卡，很快就办完迁出。</p><h3 id="邮寄迁出到天津海河人才拿到户籍页"><a href="#邮寄迁出到天津海河人才拿到户籍页" class="headerlink" title="邮寄迁出到天津海河人才拿到户籍页"></a>邮寄迁出到天津海河人才拿到户籍页</h3><p>有个纸条会写明你办完迁出所需的资料需，按要求邮寄回海河人才。</p><p>存档上报地址及常住人口登记表下载地址<br><a href="http://hhycjh.tjrc.com.cn/cddy.jsp">http://hhycjh.tjrc.com.cn/cddy.jsp</a><br>具体要求如图<br><img src="https://pic3.zhimg.com/80/v2-636b306eb83954b61303a4200f9bebda_720w.jpg" alt="准迁"><br>注意事项：<br><img src="https://pic4.zhimg.com/80/v2-f817d7eb84d74861a4f59a919edccd87_720w.jpg" alt="notes"></p><p>群友反馈最新收到这纸条，这个可能是划掉的。因为本来邮寄就没有，但是之前区域工作人员问题，可能没有划这条线导致仔细的同学就会发现少东西而担心。</p><p>那真正的存档人员证明信长什么样呢？如下。<br><img src="https://pic2.zhimg.com/80/v2-812bc9e460c8dcd27c65d18901131b35_720w.jpg" alt="存档证明信"></p><p>ps:有些区是有这个证明信的，有些区是没有的。</p><p>实际操作记录：</p><p><strong>5月10日 邮寄迁出到海河人才</strong></p><h3 id="借户口页换取身份证"><a href="#借户口页换取身份证" class="headerlink" title="借户口页换取身份证"></a>借户口页换取身份证</h3><p>公众号查询户籍是否开通，如果已经开通，就可以去北方人才去取户口页和换取身份证了</p><p>5月19日户籍状态已开通，具体流程如下：<br><a href="https://zhuanlan.zhihu.com/p/143233125">https://zhuanlan.zhihu.com/p/143233125</a></p><p>最新（2020年9月15日）群友反馈，目前河西户口页也支持邮寄。真正做到了拿到天津户口，不用去一次天津。<br><img src="https://pic3.zhimg.com/80/v2-199735768099163dab8953c82bc76bb6_720w.jpg" alt="户口页"><br>ps: 如果你不买房或者其他不用到身份证的话，拿到户口页办理户口的整个过程已经完成。</p><h3 id="links"><a href="#links" class="headerlink" title="links"></a>links</h3><p><a href="https://zhuanlan.zhihu.com/p/143207251">https://zhuanlan.zhihu.com/p/143207251</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;落户群聊天记录词云展示&lt;br&gt;&lt;img src=&quot;https://pic3.zhimg.com/80/v2-cb6d7af83845a67bfd679b9f03782f86_720w.jpg&quot; alt=&quot;天津落户沟通交流群词云&quot;&gt;&lt;/p&gt;
&lt;p&gt;从新系统（6月8号起）上线到现在（2020年8月10号），已经有不少同学拿到准迁，根据群友反馈的不同时间点，小结一下最近的情况。&lt;/p&gt;
&lt;p&gt;新系统从线上申请到拿到准迁证，大概就2个月左右，其实我感觉速度还不错。只是有些环节可能等待的有些长。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://pic4.zhimg.com/80/v2-567a25fd3b079a85c81e6a076d0aecc3_720w.jpg&quot; alt=&quot;落户过程时间点&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="生活" scheme="http://www.wiredtiger.org/categories/%E7%94%9F%E6%B4%BB/"/>
    
    
      <category term="落户" scheme="http://www.wiredtiger.org/tags/%E8%90%BD%E6%88%B7/"/>
    
  </entry>
  
  <entry>
    <title>使用confd+nacos以无侵入方式管理nginx</title>
    <link href="http://www.wiredtiger.org/2020/04/19/2020-04-19-confd-nacos-notes/"/>
    <id>http://www.wiredtiger.org/2020/04/19/2020-04-19-confd-nacos-notes/</id>
    <published>2020-04-18T16:00:00.000Z</published>
    <updated>2020-11-19T08:46:11.125Z</updated>
    
    <content type="html"><![CDATA[<h3 id="confd部署"><a href="#confd部署" class="headerlink" title="confd部署"></a>confd部署</h3><pre class="language-none"><code class="language-none">mkdir -p $GOPATH&#x2F;src&#x2F;github.com&#x2F;kelseyhightowerwget https:&#x2F;&#x2F;github.com&#x2F;nacos-group&#x2F;nacos-confd&#x2F;archive&#x2F;v0.19.2.tar.gztar -xvf v0.19.2.tar.gz -C $GOPATH&#x2F;src&#x2F;github.com&#x2F;kelseyhightowercd $GOPATH&#x2F;src&#x2F;github.com&#x2F;kelseyhightower&#x2F;nacos-confd-0.19.1makesudo cp bin&#x2F;confd &#x2F;usr&#x2F;local&#x2F;bin.&#x2F;confd -versionconfd 0.17.0-dev (Git SHA: , Go Version: go1.14.2)</code></pre><a id="more"></a><h3 id="confd的配置"><a href="#confd的配置" class="headerlink" title="confd的配置"></a>confd的配置</h3><p>confd.toml为confd服务本身的配置文件，主要记录了使用的存储后端、协议、confdir等参数。<br>/etc/confd/confd.toml by default<br>存储后端nacos配置：<br><pre class="language-none"><code class="language-none">backend &#x3D; &quot;nacos&quot;confdir &#x3D; &quot;&#x2F;etc&#x2F;confd&quot;#log-level &#x3D; &quot;debug&quot;interval &#x3D; 5nodes &#x3D; [  &quot;http:&#x2F;&#x2F;192.168.1.101:8848&quot;,]scheme &#x3D; &quot;http&quot;watch &#x3D; true</code></pre></p><h3 id="创建confdir"><a href="#创建confdir" class="headerlink" title="创建confdir"></a>创建confdir</h3><p>confdir底下包含两个目录:</p><p>conf.d:confd的配置文件，主要包含配置的生成逻辑，例如模板源，后端存储对应的keys，命令执行等。<br>templates:配置模板Template，即基于不同组件的配置，修改为符合 Golang text templates的模板文件。</p><p>参数说明：</p><p>必要参数<br>dest (string) - The target file.<br>keys (array of strings) - An array of keys.<br>src (string) - The relative path of a configuration template.</p><p>可选参数<br>gid (int) - The gid that should own the file. Defaults to the effective gid.<br>mode (string) - The permission mode of the file.<br>uid (int) - The uid that should own the file. Defaults to the effective uid.<br>reload_cmd (string) - The command to reload config.<br>check_cmd (string) - The command to check config. Use `` to reference the rendered source template.<br>prefix (string) - The string to prefix to keys.<br><pre class="language-none"><code class="language-none">mkdir -p &#x2F;etc&#x2F;confd&#x2F;&#123;conf.d,templates&#125;cd conf.d ---newsinfo.toml[template]src &#x3D; &quot;newsinfo.conf.tmpl&quot;dest &#x3D; &quot;&#x2F;tmp&#x2F;newsinfo.conf&quot;#prefix &#x3D; &quot;&#x2F;nginx&#x2F;newsinfo&quot;keys &#x3D; [    &quot;&#x2F;nginx&#x2F;newsinfo&#x2F;dev&#x2F;newsinfo&#x2F;conf&quot;,]#check_cmd &#x3D; &quot;&#x2F;usr&#x2F;local&#x2F;nginx&#x2F;sbin&#x2F;nginx -t -c &#123;&#123;.src&#125;&#125;&quot;#reload_cmd &#x3D; &quot;&#x2F;usr&#x2F;local&#x2F;nginx&#x2F;sbin&#x2F;nginx -s reload&quot;---newsinfo.conf.tmpl&#123;&#123;$data :&#x3D; json (getv &quot;&#x2F;nginx&#x2F;newsinfo&#x2F;dev&#x2F;newsinfo&#x2F;conf&quot;)&#125;&#125;&#123;&#123;$locations :&#x3D; $data.location&#125;&#125;&#123;&#123;range $locations &#125;&#125;upstream &#123;&#123; $data.usage_prefix &#125;&#125;&#123;&#123; .interface &#125;&#125; &#123;     &#123;&#123; range .upstream.backend &#125;&#125;     server &#123;&#123; .&#125;&#125;; &#123;&#123;end&#125;&#125;&#125;&#123;&#123; end &#125;&#125;server &#123;    listen       80;    server_name  &#123;&#123; $data.server_name &#125;&#125;    location &#x2F; &#123;        root   html;        index  index.html index.htm;        proxy_connect_timeout    30s;        proxy_set_header Host $host:$server_port;        proxy_set_header X-Real-IP $remote_addr;        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;        proxy_pass     http:&#x2F;&#x2F;debug_ready_sohuzixun;    &#125;    &#123;&#123;range $locations &#125;&#125;    location ^~ &#x2F;&#123;&#123; .interface &#125;&#125; &#123;        proxy_pass  http:&#x2F;&#x2F;&#123;&#123; $data.usage_prefix &#125;&#125;&#123;&#123; .interface &#125;&#125;;        proxy_connect_timeout   30s;        proxy_set_header Host $host:$server_port;        proxy_set_header X-Real-IP $remote_addr;        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;    &#125;    &#123;&#123; end &#125;&#125;&#125;</code></pre></p><h3 id="confd启动"><a href="#confd启动" class="headerlink" title="confd启动"></a>confd启动</h3><p>confd支持以daemon或者onetime两种模式运行<br><pre class="language-none"><code class="language-none">&#x2F;usr&#x2F;local&#x2F;bin&#x2F;confd -config-file &#x2F;etc&#x2F;confd&#x2F;conf&#x2F;confd.tomlnohup &#x2F;usr&#x2F;local&#x2F;bin&#x2F;confd -config-file &#x2F;etc&#x2F;confd&#x2F;conf&#x2F;confd.toml &gt; confd.log 2&gt;&amp;1 &amp;</code></pre></p><h3 id="nacos部署"><a href="#nacos部署" class="headerlink" title="nacos部署"></a>nacos部署</h3><h3 id="问题汇总"><a href="#问题汇总" class="headerlink" title="问题汇总"></a>问题汇总</h3><p>问题描述：<br> -bash: .confd/: 无法执行二进制文件<br>问题解决：<br>同步到服务器上，make</p><p>links:<br><a href="https://github.com/kelseyhightower/confd/tree/master/docs">https://github.com/kelseyhightower/confd/tree/master/docs</a></p>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;confd部署&quot;&gt;&lt;a href=&quot;#confd部署&quot; class=&quot;headerlink&quot; title=&quot;confd部署&quot;&gt;&lt;/a&gt;confd部署&lt;/h3&gt;&lt;pre class=&quot;language-none&quot;&gt;&lt;code class=&quot;language-none&quot;&gt;mkdir -p $GOPATH&amp;#x2F;src&amp;#x2F;github.com&amp;#x2F;kelseyhightower
wget https:&amp;#x2F;&amp;#x2F;github.com&amp;#x2F;nacos-group&amp;#x2F;nacos-confd&amp;#x2F;archive&amp;#x2F;v0.19.2.tar.gz
tar -xvf v0.19.2.tar.gz -C $GOPATH&amp;#x2F;src&amp;#x2F;github.com&amp;#x2F;kelseyhightower

cd $GOPATH&amp;#x2F;src&amp;#x2F;github.com&amp;#x2F;kelseyhightower&amp;#x2F;nacos-confd-0.19.1
make
sudo cp bin&amp;#x2F;confd &amp;#x2F;usr&amp;#x2F;local&amp;#x2F;bin

.&amp;#x2F;confd -version
confd 0.17.0-dev (Git SHA: , Go Version: go1.14.2)
&lt;/code&gt;&lt;/pre&gt;
    
    </summary>
    
      <category term="Nginx" scheme="http://www.wiredtiger.org/categories/Nginx/"/>
    
    
      <category term="confd nacos" scheme="http://www.wiredtiger.org/tags/confd-nacos/"/>
    
  </entry>
  
  <entry>
    <title>Grafana的版本升级和数据迁移</title>
    <link href="http://www.wiredtiger.org/2020/03/16/2020-03-16-grafana-update/"/>
    <id>http://www.wiredtiger.org/2020/03/16/2020-03-16-grafana-update/</id>
    <published>2020-03-15T16:00:00.000Z</published>
    <updated>2020-11-02T02:10:43.333Z</updated>
    
    <content type="html"><![CDATA[<p>下载最新的grafana版本<br><a href="https://grafana.com/grafana/download">官网下载地址</a></p><pre class="language-none"><code class="language-none">wget https:&#x2F;&#x2F;dl.grafana.com&#x2F;oss&#x2F;release&#x2F;grafana-6.7.4.linux-amd64.tar.gztar -zxvf grafana-6.7.4.linux-amd64.tar.gz</code></pre><a id="more"></a><p>修改<br>/etc/systemd/system/grafana-server.service<br><pre class="language-none"><code class="language-none">[Unit]Description&#x3D;Grafana 6.7Documentation&#x3D;http:&#x2F;&#x2F;docs.grafana.orgWants&#x3D;network-online.targetAfter&#x3D;network-online.target[Service]Type&#x3D;notifyRestart&#x3D;on-failureWorkingDirectory&#x3D;&#x2F;data&#x2F;apps&#x2F;opt&#x2F;grafanaRuntimeDirectory&#x3D;grafanaRuntimeDirectoryMode&#x3D;0750ExecStart&#x3D;&#x2F;data&#x2F;apps&#x2F;opt&#x2F;grafana&#x2F;bin&#x2F;grafana-server --config&#x3D;&#x2F;data&#x2F;apps&#x2F;opt&#x2F;grafana&#x2F;conf&#x2F;defaults.iniLimitNOFILE&#x3D;10000TimeoutStopSec&#x3D;20[Install]WantedBy&#x3D;multi-user.target</code></pre></p><p>迁移之前grafana下的数据到data目录下，完成数据迁移。</p><p>配置文件<br><pre class="language-none"><code class="language-none">域名转发根目录跳转# The full public facing url#root_url &#x3D; %(protocol)s:&#x2F;&#x2F;%(domain)s:%(http_port)s&#x2F;root_url &#x3D; http:&#x2F;&#x2F;xxx.&#x2F;grafana开启匿名登陆#################################### Anonymous Auth ######################[auth.anonymous]# enable anonymous accessenabled &#x3D; true</code></pre></p><p>部署好新的grafna后，修改nginx代理解析即可。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;下载最新的grafana版本&lt;br&gt;&lt;a href=&quot;https://grafana.com/grafana/download&quot;&gt;官网下载地址&lt;/a&gt;&lt;/p&gt;
&lt;pre class=&quot;language-none&quot;&gt;&lt;code class=&quot;language-none&quot;&gt;wget https:&amp;#x2F;&amp;#x2F;dl.grafana.com&amp;#x2F;oss&amp;#x2F;release&amp;#x2F;grafana-6.7.4.linux-amd64.tar.gz
tar -zxvf grafana-6.7.4.linux-amd64.tar.gz&lt;/code&gt;&lt;/pre&gt;
    
    </summary>
    
      <category term="Linux" scheme="http://www.wiredtiger.org/categories/Linux/"/>
    
    
      <category term="监控" scheme="http://www.wiredtiger.org/tags/%E7%9B%91%E6%8E%A7/"/>
    
  </entry>
  
  <entry>
    <title>nginx实现四层代理</title>
    <link href="http://www.wiredtiger.org/2020/03/14/2020-03-14-nginx-tcp-proxy-stream/"/>
    <id>http://www.wiredtiger.org/2020/03/14/2020-03-14-nginx-tcp-proxy-stream/</id>
    <published>2020-03-13T16:00:00.000Z</published>
    <updated>2020-11-20T10:37:13.403Z</updated>
    
    <content type="html"><![CDATA[<p>Nginx 从1.9.0开始发布ngx_stream_core_module模块，该模块支持tcp代理及负载均衡。</p><p>在编译时通过指定–with-stream参数来激活这个模块。</p><p>Nginx编译后参数如下<br><pre class="language-none"><code class="language-none">-prefix&#x3D;&#x2F;usr&#x2F;local&#x2F;nginx --with-http_stub_status_module --with-http_ssl_module --with-http_realip_module --with-pcre --with-stream --with-http_perl_module --with-http_secure_link_module --with-http_auth_request_module --with-http_sub_module --with-http_gzip_static_module --add-module&#x3D;..&#x2F;nginx-module-vts --add-module&#x3D;..&#x2F;nginx-upsync-module</code></pre><br><a id="more"></a></p><h3 id="实现SSH转发"><a href="#实现SSH转发" class="headerlink" title="实现SSH转发"></a>实现SSH转发</h3><p>stream代码块与http代码块同级别<br><pre class="language-none"><code class="language-none">stream &#123;      upstream ssh_proxy &#123;        hash $remote_addr consistent;        server 10.16.76.116:22;        server 10.16.76.119:22;    &#125;    server &#123;        listen 2222;        proxy_connect_timeout 1s;        proxy_timeout 300s;        proxy_pass ssh_proxy;            &#125;&#125;</code></pre></p><h3 id="MYSQL负载均衡"><a href="#MYSQL负载均衡" class="headerlink" title="MYSQL负载均衡"></a>MYSQL负载均衡</h3><pre class="language-none"><code class="language-none">stream &#123;    upstream mysql_proxy &#123;#hash $remote_addr consistent;        server 10.18.70.70:3307;    &#125;    server &#123;        listen 3333;        proxy_connect_timeout 1s;        proxy_timeout 300s;        proxy_pass mysql_proxy;    &#125;&#125;</code></pre><h3 id="测试验证"><a href="#测试验证" class="headerlink" title="测试验证"></a>测试验证</h3><pre class="language-none"><code class="language-none">ssh -p 2222  root@nginx_ipmysql -P 3333  -h nginx_ip -u mysql_user -p</code></pre><h3 id="notes"><a href="#notes" class="headerlink" title="notes"></a>notes</h3><p>stream日志模块 nginx 1.11.4之后版本才支持。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Nginx 从1.9.0开始发布ngx_stream_core_module模块，该模块支持tcp代理及负载均衡。&lt;/p&gt;
&lt;p&gt;在编译时通过指定–with-stream参数来激活这个模块。&lt;/p&gt;
&lt;p&gt;Nginx编译后参数如下&lt;br&gt;&lt;pre class=&quot;language-none&quot;&gt;&lt;code class=&quot;language-none&quot;&gt;-prefix&amp;#x3D;&amp;#x2F;usr&amp;#x2F;local&amp;#x2F;nginx --with-http_stub_status_module --with-http_ssl_module --with-http_realip_module --with-pcre --with-stream --with-http_perl_module --with-http_secure_link_module --with-http_auth_request_module --with-http_sub_module --with-http_gzip_static_module --add-module&amp;#x3D;..&amp;#x2F;nginx-module-vts --add-module&amp;#x3D;..&amp;#x2F;nginx-upsync-module&lt;/code&gt;&lt;/pre&gt;&lt;br&gt;
    
    </summary>
    
      <category term="Linux" scheme="http://www.wiredtiger.org/categories/Linux/"/>
    
    
      <category term="Nginx" scheme="http://www.wiredtiger.org/tags/Nginx/"/>
    
  </entry>
  
  <entry>
    <title>Prometheus Grafana学习笔记</title>
    <link href="http://www.wiredtiger.org/2020/03/13/2020-03-14-grafana-prometheus-notes-md/"/>
    <id>http://www.wiredtiger.org/2020/03/13/2020-03-14-grafana-prometheus-notes-md/</id>
    <published>2020-03-12T16:00:00.000Z</published>
    <updated>2020-10-28T01:53:34.400Z</updated>
    
    <content type="html"><![CDATA[<h3 id="prometheus-大内存问题"><a href="#prometheus-大内存问题" class="headerlink" title="prometheus 大内存问题"></a>prometheus 大内存问题</h3><p>随着规模变大，prometheus需要的cpu和内存都会升高，内存一般先达到瓶颈，这个时候要么加内存，要么集群分片减少单机指标。<br>原因：<br>1、prometheus 的内存消耗主要是因为每隔2小时做一个 block 数据落盘，落盘之前所有数据都在内存里面，因此和采集量有关。<br>2、加载历史数据时，是从磁盘到内存的，查询范围越大，内存越大。这里面有一定的优化空间<br>3、一些不合理的查询条件也会加大内存，如 group、大范围rate</p><p>sample 数量超过了 200 万，就不要单实例了，做下分片，<br>然后通过victoriametrics，thanos，trickster等方案合并数据</p><p>使用了thanos方案</p><a id="more"></a><p>磁盘预估方法</p><p>Bytes per Sample<br>rate(prometheus_tsdb_compaction_chunk_size_bytes_sum[1d])/rate(prometheus_tsdb_compaction_chunk_samples_sum[1d])</p><p>每秒获取的样本数<br>rate(prometheus_tsdb_head_samples_appended_total[1h])</p><p>磁盘容量预估<br>磁盘大小 = 保留时间 <em> 每秒获取样本数 </em> 样本大小</p><p>2h <em> 51935.72524407252 </em> 1.5 Bytes</p><p>2<em>60</em>60<em>1.6</em>51935=570M</p><h3 id="prometheus-内存-磁盘预估"><a href="#prometheus-内存-磁盘预估" class="headerlink" title="prometheus 内存 磁盘预估"></a>prometheus 内存 磁盘预估</h3><p>查看多少台node_exporter<br>count(node_exporter_build_info)</p><p>908 台机器 - 180 视频商业</p><p>node<em>export<br>curl -s <a href="http://localhost:9100/metrics">http://localhost:9100/metrics</a> | grep -v “#”|grep “node</em>“ |wc -l<br>2448</p><p>测量点(即样本数量)</p><p>指标统计</p><p>Promethues 压缩样本使用磁盘大小公式为 :<br>compact_data_disk_usage = (romethues 压缩样本使用磁盘大小公式为 :<br>compact_data_disk_usage = 2448/prometheus.node.exporter.scrape_interval <em> nodeNum </em> prometheus.storage.retention.time (in seconds) * 单个样本平均大小(1-2 bytes)</p><p>2448/15<em>908</em>(24<em>60</em>60)*2=23.84789G</p><p>WAL 文件大小取决于Prometheus 留存于内存的活跃样本的大小. 而留存于内存的活跃样本的大小又取决于每秒获取样本数和活跃样本留存内存时间.<br>记录活跃样本信息的 WAL 文件都是 raw data, 故大小比经过编码之后的样本大得多.<br>Prometheus 官方文档中说明至少会保存3个 write-ahead log files(每一个最大为128M), 如果实际使用中留存内存的样本数量非常大,<br>那么用来记录样本的 WAL 文件可能需要不止三个</p><p>计算 wal file 之前需要计算留存于内存的活跃样本占用内存大小<br>active_data_mem_uage = (534 / prometheus.node.exporter.scrape_interval + 481 / prometheus.tdh.exporter.scrape_interval) <em> nodeNum </em> prometheus.max-block-duration(in seconds) * 单个样本平均大小(1-2 bytes)</p><p>active_data_mem_uage = 2448/15 <em> 908 </em> (24 <em> 60 </em> 60) <em> 2 = 25606471680 bytes = 23.84789G<br>Prometheus 编码之后的样本平均大小为1~2 bytes, 而未编码的 double类型数据为 8 bytes, 故raw data最大可为编码之后的样本数据的八倍. 可以粗略的认为 WAL file 大小和 样本 raw data近似相等, 故可以得出公式:<br>wal_file_disk_usage = active_data_mem_uage </em> (8 / 1) = 190G</p><p>综上所述, total_disk_usage = compact_data_disk_usage + wal_file_disk_usage, 考虑集群的扩展性，建议预留磁盘空间为 total_disk_usage * 5.</p><h3 id="thanos部署"><a href="#thanos部署" class="headerlink" title="thanos部署"></a>thanos部署</h3><p>thanos version 2.13.0 版本</p><p>prometheus部署<br>/etc/systemd/system/prometheus.service<br><pre class="language-none"><code class="language-none">[Unit]Description&#x3D;prometheus_mediaAfter&#x3D;network.target[Service]Type&#x3D;simpleUser&#x3D;rootExecStart&#x3D;&#x2F;data&#x2F;apps&#x2F;prometheus&#x2F;prometheus --config.file&#x3D;&#x2F;data&#x2F;apps&#x2F;prometheus&#x2F;prometheus.yml --storage.tsdb.path&#x3D;&#x2F;data&#x2F;apps&#x2F;prometheus&#x2F;data --storage.tsdb.retention.time&#x3D;1d --web.enable-admin-api --web.enable-lifecycleRestart&#x3D;on-failure[Install]WantedBy&#x3D;multi-user.target####prometheus.service#prometheus_media.service#prometheus_shipin#prometheus_zixun</code></pre></p><p>thanos启动<br><pre class="language-none"><code class="language-none">sidecar启动命令：nohup .&#x2F;thanos sidecar --tsdb.path &#x2F;data&#x2F;apps&#x2F;prometheus&#x2F;media --prometheus.url http:&#x2F;&#x2F;localhost:9090 --http-address 0.0.0.0:19191 --grpc-address 0.0.0.0:19091 &gt; sd_media.log 2&gt;&amp;1 &amp;nohup .&#x2F;thanos sidecar --tsdb.path &#x2F;data&#x2F;apps&#x2F;prometheus&#x2F;shipin --prometheus.url http:&#x2F;&#x2F;localhost:9092 --http-address 0.0.0.0:19192 --grpc-address 0.0.0.0:19092 &gt; sd_shipin.log 2&gt;&amp;1 &amp;nohup .&#x2F;thanos sidecar --tsdb.path &#x2F;data&#x2F;apps&#x2F;prometheus&#x2F;zixun --prometheus.url http:&#x2F;&#x2F;localhost:9095 --http-address 0.0.0.0:19193 --grpc-address 0.0.0.0:19093 &gt; sd_zixun.log 2&gt;&amp;1 &amp;query启动命令：nohup .&#x2F;thanos query --http-address 0.0.0.0:29090 --grpc-address 0.0.0.0:29091 --query.replica-label monitor --store 10.16.12.54:19091 --store 10.16.12.54:19092 --store 10.18.94.40:19093 &gt; qu_media.log 2&gt;&amp;1 &amp;nohup .&#x2F;thanos query --http-address 0.0.0.0:29092 --grpc-address 0.0.0.0:29093 --query.replica-label monitor --store 10.16.12.54:19091 --store 10.16.12.54:19092 --store 10.18.94.40:19093 &gt; qu_shipin.log 2&gt;&amp;1 &amp;nohup .&#x2F;thanos query --http-address 0.0.0.0:29094 --grpc-address 0.0.0.0:29095 --query.replica-label monitor --store 10.16.12.54:19091 --store 10.16.12.54:19092 --store 10.18.94.40:19093 &gt; qu_zixun.log 2&gt;&amp;1 &amp;</code></pre><br>nginx负载均衡查询端<br><pre class="language-none"><code class="language-none">upstream thanos &#123;    server 192.168.1.111:29094 max_fails&#x3D;2 fail_timeout&#x3D;15s;    server 192.168.1.112:29090 max_fails&#x3D;2 fail_timeout&#x3D;15s;    server 192.168.1.113:29092 max_fails&#x3D;2 fail_timeout&#x3D;15s;&#125;server &#123;    listen       80;    server_name  xxx;    #charset koi8-r;    access_log  &#x2F;data&#x2F;logs&#x2F;nginx&#x2F;thanos.log;    location &#x2F; &#123;        proxy_connect_timeout    30s;        proxy_set_header Host $host:$server_port;        proxy_set_header X-Real-IP $remote_addr;        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;        access_log    &#x2F;data&#x2F;logs&#x2F;nginx&#x2F;thanso.log;        proxy_pass http:&#x2F;&#x2F;thanos;    &#125;&#125;</code></pre></p><h3 id="Grafana设置免密登录"><a href="#Grafana设置免密登录" class="headerlink" title="Grafana设置免密登录"></a>Grafana设置免密登录</h3><pre class="language-none"><code class="language-none">[auth.anonymous]enabled &#x3D; trueorg_name &#x3D; Main Org.org_role &#x3D; Viewer</code></pre><h3 id="Grafana设置"><a href="#Grafana设置" class="headerlink" title="Grafana设置"></a>Grafana设置</h3><p>label_values(node_uname_info, job)</p><p>instance=~”$node”,mode=”system”</p><h3 id="Grafana添加告警"><a href="#Grafana添加告警" class="headerlink" title="Grafana添加告警"></a>Grafana添加告警</h3><p>开启anonymous后，ui Server Admin设置orgs 设置Main Org. 与org_name一致。</p><p>PromQL<br>{} 过滤时间序列数据<br>[] 范围样本区间</p><h3 id="常用运维命令"><a href="#常用运维命令" class="headerlink" title="常用运维命令"></a>常用运维命令</h3><pre class="language-none"><code class="language-none">.&#x2F;tsdb ls custom_allBLOCK ULID                  MIN TIME       MAX TIME       NUM SAMPLES  NUM CHUNKS  NUM SERIES01E4JAJCEZZRTTQ56CM1C1VKW1  1585447200000  1585454400000  373837607    3112298     78308501E4JHE3EKB5252S5060RS88GF  1585454400000  1585461600000  373910606    3114077     783026</code></pre><h3 id="参考地址："><a href="#参考地址：" class="headerlink" title="参考地址："></a>参考地址：</h3><p><a href="https://prometheus.io/docs/guides/node-exporter/">https://prometheus.io/docs/guides/node-exporter/</a><br><a href="http://support.transwarp.cn/t/topic/3226">http://support.transwarp.cn/t/topic/3226</a></p>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;prometheus-大内存问题&quot;&gt;&lt;a href=&quot;#prometheus-大内存问题&quot; class=&quot;headerlink&quot; title=&quot;prometheus 大内存问题&quot;&gt;&lt;/a&gt;prometheus 大内存问题&lt;/h3&gt;&lt;p&gt;随着规模变大，prometheus需要的cpu和内存都会升高，内存一般先达到瓶颈，这个时候要么加内存，要么集群分片减少单机指标。&lt;br&gt;原因：&lt;br&gt;1、prometheus 的内存消耗主要是因为每隔2小时做一个 block 数据落盘，落盘之前所有数据都在内存里面，因此和采集量有关。&lt;br&gt;2、加载历史数据时，是从磁盘到内存的，查询范围越大，内存越大。这里面有一定的优化空间&lt;br&gt;3、一些不合理的查询条件也会加大内存，如 group、大范围rate&lt;/p&gt;
&lt;p&gt;sample 数量超过了 200 万，就不要单实例了，做下分片，&lt;br&gt;然后通过victoriametrics，thanos，trickster等方案合并数据&lt;/p&gt;
&lt;p&gt;使用了thanos方案&lt;/p&gt;
    
    </summary>
    
      <category term="Linux" scheme="http://www.wiredtiger.org/categories/Linux/"/>
    
    
      <category term="监控" scheme="http://www.wiredtiger.org/tags/%E7%9B%91%E6%8E%A7/"/>
    
  </entry>
  
  <entry>
    <title>Redis Cluster搭建、扩容、缩容</title>
    <link href="http://www.wiredtiger.org/2019/10/27/2019-10-27-redis-cluster-install-manual/"/>
    <id>http://www.wiredtiger.org/2019/10/27/2019-10-27-redis-cluster-install-manual/</id>
    <published>2019-10-26T16:00:00.000Z</published>
    <updated>2020-11-20T10:37:53.547Z</updated>
    
    <content type="html"><![CDATA[<h4 id="集群机器列表"><a href="#集群机器列表" class="headerlink" title="集群机器列表"></a>集群机器列表</h4><p>redis版本 redis-cli 3.2.11<br><pre class="language-none"><code class="language-none">10.16.76.11610.16.76.11710.16.76.119集群安装跑ansible脚本master 10.16.76.116:6000  10.16.76.117:6000  10.16.76.119:6000    slave10.16.76.116:700010.16.76.117:700010.16.76.119:7000</code></pre><br><a id="more"></a></p><h4 id="初始化集群"><a href="#初始化集群" class="headerlink" title="初始化集群"></a>初始化集群</h4><p>配置主节点</p><p>方法1:<br>redis-trib.rb 直接初始化机器。</p><p>方法2:</p><p>a. 添加节点： cluster meet ip port<br>CLUSTER nodes<br>CLUSTER info</p><p>b. 分配槽点 16384<br>5462+5461+5461</p><p>sh addslots.sh分配槽点</p><p>cluster addslots {0…5461}<br>cluster addslots {5462…10922}<br>cluster addslots {10923…16384}</p><p>以上cluste就完成了，是单点的。<br>c.保证各个节点的高可用，给每个主节点添加一个从节点。<br>cluster meet ip port</p><p>slave节点上关联,必须在对应的从节点上执行<br>cluster replicate node_id </p><pre class="language-none"><code class="language-none">3d401353114a1fd6359e51859f022dfdc5861bc9 10.16.76.116:6000 myself,master - 0 0 1 connected 0-5461ec1e5df312f947c540cc64fac3cfe3aa8df1799a 10.16.76.117:6000 master - 0 1571987989678 0 connected 5462-109220af9d4868039dfe5c9dd212d75695a2607ada12f 10.16.76.119:6000 master - 0 1571987994688 2 connected 10923-16383</code></pre><h3 id="测试数据"><a href="#测试数据" class="headerlink" title="测试数据"></a>测试数据</h3><p>set a,b,c分别hash到不同节点<br><pre class="language-none"><code class="language-none">get a-&gt; Redirected to slot [15495] located at 10.16.76.119:6000&quot;1&quot;10.16.76.119:6000&gt; get b-&gt; Redirected to slot [3300] located at 10.16.76.116:6000&quot;2&quot;10.16.76.116:6000&gt; get c-&gt; Redirected to slot [7365] located at 10.16.76.117:6000&quot;3&quot;</code></pre></p><h3 id="Redis-Cluster常用命令"><a href="#Redis-Cluster常用命令" class="headerlink" title="Redis Cluster常用命令"></a>Redis Cluster常用命令</h3><pre class="language-none"><code class="language-none">CLUSTER info：打印集群的信息。CLUSTER nodes：列出集群当前已知的所有节点（node）的相关信息。CLUSTER meet &lt;ip&gt; &lt;port&gt;：将ip和port所指定的节点添加到集群当中。CLUSTER replicate &lt;node_id&gt;：将当前节点设置为指定节点的从节点。CLUSTER saveconfig：手动执行命令保存保存集群的配置文件，集群默认在配置修改的时候会自动保存配置文件。CLUSTER failover：手动进行故障转移，在slave上执行。CLUSTER keyslot &lt;key&gt;：列出key被放置在哪个槽上。CLUSTER countkeysinslot &lt;slot&gt;：返回槽目前包含的键值对数量。CLUSTER getkeysinslot &lt;slot&gt; &lt;count&gt;：返回count个槽中的键。迁移槽和数据相关命令CLUSTER setslot &lt;slot&gt; importing &lt;node_id&gt; 从 node_id (sourceNodeId)指定的节点中导入槽 slot 到本节点CLUSTER setslot &lt;slot&gt; migrating &lt;node_id&gt; 将本节点的槽迁移到指定的节点node_id (targetNodeId)中。CLUSTER getkeysinslot &lt;slot&gt; &lt;count&gt;：源节点循环执行，获取count个属于槽&#123;slot&#125;的键。在源节点迁移槽位中的key到目标节点：MIGRATE host port key destination-db timeout [COPY] [REPLACE]逐个迁移：migrate 10.16.76.116 8000 key:test:x1 0 5000 replace批量迁移：migrate 10.16.76.116 8000 &quot;&quot; 0 5000 keys key:test:x1 key:test:x2 key:test:x3CLUSTER setslot &lt;slot&gt; node &lt;node_id&gt; :通知槽分配给目标节点，node_id (targetNodeId)cluster setslot &lt;slot&gt; stable取消 slot 的导入（import）或者迁移（migrate）。</code></pre><h3 id="集群扩容"><a href="#集群扩容" class="headerlink" title="集群扩容"></a>集群扩容</h3><pre class="language-none"><code class="language-none">10.16.76.116:800010.16.76.117:800010.16.76.119:8000原集群槽点5461-5460-54604096-4096-4096-40963d401353114a1fd6359e51859f022dfdc5861bc9 10.16.76.116:6000 master - 0 1572246866662 8 connected 0-5461f9fb5268c416b82dc4ea7d4948895454be4186a0 10.16.76.116:8000 master - 0 1572246863153 0 connected0af9d4868039dfe5c9dd212d75695a2607ada12f 10.16.76.119:6000 master - 0 1572246869667 2 connected 10923-16383ec1e5df312f947c540cc64fac3cfe3aa8df1799a 10.16.76.117:6000 master - 0 1572246864657 9 connected 5462-10922</code></pre><h3 id="迁移数据流程"><a href="#迁移数据流程" class="headerlink" title="迁移数据流程"></a>迁移数据流程</h3><pre class="language-none"><code class="language-none">目的节点：CLUSTER setslot 4096 importing 3d401353114a1fd6359e51859f022dfdc5861bc9源节点：CLUSTER setslot 4096 migrating f9fb5268c416b82dc4ea7d4948895454be4186a0获取count属于槽slot的键:CLUSTER getkeysinslot 4096 100迁移数据到目的节点：migrate 10.16.76.116 8000 key:test:5028 0 5000 replacemigrate 10.16.76.116 8000 &quot;&quot; 0 5000 keys key:test:68253 key:test:79212 遍历所有主节点执行：CLUSTER setslot 4096 node f9fb5268c416b82dc4ea7d4948895454be4186a0</code></pre><h3 id="集群收缩"><a href="#集群收缩" class="headerlink" title="集群收缩"></a>集群收缩</h3><pre class="language-none"><code class="language-none">redis-trib.rb reshard 10.16.76.116:6000下线节点槽点迁出完成后，剩剩下的步骤需要让集群忘记该节点。线上操场不建议直接使用cluster forget下线节点建议使用redis-trib.rb del-node &#123;host:port&#125; &#123;downNodeId&#125;从节点redis-trib.rb del-node 10.16.76.117:8000 75202671eb18e504357ea8761ab6dc729b8526a2主节点redis-trib.rb del-node 10.16.76.116:8000 f9fb5268c416b82dc4ea7d4948895454be4186a0</code></pre><h3 id="故障转移"><a href="#故障转移" class="headerlink" title="故障转移"></a>故障转移</h3><p>主观下线： 指某个节点认为另一个节点不可用，即下线状态。</p><p>客观下线： 集群内多个节点都认为该节点不可用。</p><h3 id="集群倾斜"><a href="#集群倾斜" class="headerlink" title="集群倾斜"></a>集群倾斜</h3><p>数据倾斜</p><p>redis-trib.rb info 查看节点槽点不均的情况。<br>hash数据分别，导致集群qps差距很大。</p><h3 id="问题汇总"><a href="#问题汇总" class="headerlink" title="问题汇总"></a>问题汇总</h3><p>问题描述：<br>Moving slot 4096 from 10.16.76.116:8000 to 10.16.76.116:6000:<br>[ERR] Calling MIGRATE: ERR Syntax error, try CLIENT (LIST | KILL | GETNAME | SETNAME | PAUSE | REPLY)</p><p>问题解决：<br>1、ruby gem安装的redis库，版本不能使用最新的4.0，否则redis-trib.rb reshard 127.0.0.1:7000 重新分片时会报语法错误。<br>   卸载最新redis库，gem uninstall redis<br>   安装3.x版本，gem install redis -v 3.3.5 测试3.2.1到3.3.5都可以，4.x以上的分片报错<br>2、使用fix来进行修复，具体命令如下：<br>   redis-trib.rb fix 10.16.76.116:6000</p><h3 id="redis参数"><a href="#redis参数" class="headerlink" title="redis参数"></a>redis参数</h3><p>//connectionTimeout 连接超时（默认2000ms）<br>//soTimeout 响应超时（默认2000ms）</p>]]></content>
    
    <summary type="html">
    
      &lt;h4 id=&quot;集群机器列表&quot;&gt;&lt;a href=&quot;#集群机器列表&quot; class=&quot;headerlink&quot; title=&quot;集群机器列表&quot;&gt;&lt;/a&gt;集群机器列表&lt;/h4&gt;&lt;p&gt;redis版本 redis-cli 3.2.11&lt;br&gt;&lt;pre class=&quot;language-none&quot;&gt;&lt;code class=&quot;language-none&quot;&gt;10.16.76.116
10.16.76.117
10.16.76.119

集群安装跑ansible脚本

master 
10.16.76.116:6000  	
10.16.76.117:6000  
10.16.76.119:6000    

slave
10.16.76.116:7000
10.16.76.117:7000
10.16.76.119:7000&lt;/code&gt;&lt;/pre&gt;&lt;br&gt;
    
    </summary>
    
      <category term="Redis" scheme="http://www.wiredtiger.org/categories/Redis/"/>
    
    
      <category term="Redis" scheme="http://www.wiredtiger.org/tags/Redis/"/>
    
  </entry>
  
  <entry>
    <title>redis-migrate-tool使用详解</title>
    <link href="http://www.wiredtiger.org/2019/08/25/2019-08-25-redis-migrate-tool/"/>
    <id>http://www.wiredtiger.org/2019/08/25/2019-08-25-redis-migrate-tool/</id>
    <published>2019-08-24T16:00:00.000Z</published>
    <updated>2020-04-10T03:56:37.722Z</updated>
    
    <content type="html"><![CDATA[<h3 id="rmt介绍"><a href="#rmt介绍" class="headerlink" title="rmt介绍"></a>rmt介绍</h3><p>redis-migrate-tool 是维品会开源的一款redis数据迁移工具，基于redis复制，快速，稳定，github地址为：<a href="https://github.com/vipshop/redis-migrate-tool">https://github.com/vipshop/redis-migrate-tool</a> 。</p><ul><li>快速。</li><li>多线程。</li><li>基于redis复制。</li><li>实时迁移。</li><li>迁移过程中，源集群不影响对外提供服务。</li><li>异构迁移。</li><li>支持Twemproxy集群，redis cluster集群，rdb文件 和 aof文件。</li><li>过滤功能。</li><li>当目标集群是Twemproxy，数据会跳过Twemproxy直接导入到后端的redis。</li><li>迁移状态显示。</li><li>完善的数据抽样校验(-C redis_check)。</li></ul><p>划重点 实时迁移 迁移过程中，源集群不影响对外提供服务<br><a id="more"></a></p><h3 id="安装redis-migrate-tool"><a href="#安装redis-migrate-tool" class="headerlink" title="安装redis-migrate-tool"></a>安装redis-migrate-tool</h3><p>依赖</p><pre class="language-none"><code class="language-none">yum -y install automake libtool autoconf bzip2 git</code></pre><p>构建<br><pre class="language-none"><code class="language-none">$ cd redis-migrate-tool$ autoreconf -fvi$ .&#x2F;configure$ make$ src&#x2F;redis-migrate-tool -h</code></pre></p><p>警告</p><p>在运行工具之前，确保源redis所在的机器有足够的内存可以允许至少一个redis生成.rdb文件，如果源机器有大量足够的内存允许所有的redis生成.rdb，可以在配置文件rmt.conf设置source_safe: false。</p><p>下列命令不支持传播给target redis组，因为这些命令下的keys可能交叉了不同的目标redis节点。<br><pre class="language-none"><code class="language-none">RENAME,RENAMENX,RPOPLPUSH,BRPOPLPUSH,FLUSHALL,FLUSHDB,BITOP,MOVE,GEORADIUS,GEORADIUSBYMEMBE</code></pre></p><h3 id="redis-migrate-tool-命令详解"><a href="#redis-migrate-tool-命令详解" class="headerlink" title="redis-migrate-tool 命令详解"></a>redis-migrate-tool 命令详解</h3><p>出现下列帮助说明表示安装成功<br><pre class="language-none"><code class="language-none">This is redis-migrate-tool-0.1.0Usage: redis-migrate-tool [-?hVdIn] [-v verbosity level] [-o output file]                  [-c conf file] [-C command]                  [-f source address] [-t target address]                  [-p pid file] [-m mbuf size] [-r target role]                  [-T thread number] [-b buffer size]Options:  -h, --help             : this help  -V, --version          : show version and exit  -d, --daemonize        : run as a daemon  -I, --information      : print some useful information  -n, --noreply          : don&#39;t receive the target redis reply  -v, --verbosity&#x3D;N      : set logging level (default: 5, min: 0, max: 11)  -o, --output&#x3D;S         : set logging file (default: stderr)  -c, --conf-file&#x3D;S      : set configuration file (default: rmt.conf)  -p, --pid-file&#x3D;S       : set pid file (default: off)  -m, --mbuf-size&#x3D;N      : set mbuf size (default: 512)  -C, --command&#x3D;S        : set command to execute (default: redis_migrate)  -r, --source-role&#x3D;S    : set the source role (default: single, you can input: single, twemproxy or redis_cluster)  -R, --target-role&#x3D;S    : set the target role (default: single, you can input: single, twemproxy or redis_cluster)  -T, --thread&#x3D;N         : set how many threads to run the job(default: 4)  -b, --buffer&#x3D;S         : set buffer size to run the job (default: 140720309534720 byte, unit:G&#x2F;M&#x2F;K)  -f, --from&#x3D;S           : set source redis address (default: 127.0.0.1:6379)  -t, --to&#x3D;S             : set target redis group address (default: 127.0.0.1:6380)  -s, --step&#x3D;N           : set step (default: 1)Commands:    redis_migrate        : Migrate data from source group to target group.    redis_check          : Compare data between source group and target group. Default compare 1000 keys. You can set a key count behind.    redis_testinsert     : Just for test! Insert some string, list, set, zset and hash keys into the source redis group. Default 1000 keys. You can set key type and key count behind.</code></pre><br>部分指令解析：</p><p>-h, –help：帮助<br>-V, –version：显示版本<br>-d, –daemonize：后台进程运行<br>-I, –information：打印一些有用的信息，包括可以解析的指令（126个），不支持的指令（14个）等等<br>-v, –verbosity=N：设置日志等级。(默认: 5, 最低: 0, 最高: 11)<br>-o, –output=S：设置输出的日志文件<br>-c, –conf-file=S：设置配置文件。(默认: rmt.conf)<br>-C, –command=S：设置运行的指令(默认: redis_migrate ，迁移)。redis_check 比较源和目的，默认1000个样本key。redis_testinsert测试插入Keys，默认所有类型总共1000个。<br>-T, –thread=N：设置多少个线程用来运行工具。(默认: 4)</p><ol><li>运行迁移<pre class="language-none"><code class="language-none">$ src&#x2F;redis-migrate-tool -c rmt.conf -o log -d</code></pre>注意：-d指定为后台运行，如果再次运行可能需要杀死占用当前端口的进程。netstat -tnulp查看找到redis-migrate-tool的端口号，kill -9 [端口号]杀死再运行。</li></ol><p>指定输出日志文件为log，可通过tail -200 log等查看日志。</p><ol><li>抽样检查<pre class="language-none"><code class="language-none">$ src&#x2F;redis-migrate-tool -c rmt.conf -o log -C redis_checkCheck job is running...Checked keys: 1000Inconsistent value keys: 0Inconsistent expire keys : 0Other check error keys: 0Checked OK keys: 1000All keys checked OK!Check job finished, used 1.041s</code></pre>抽样检查源组和目标组的数据，默认为1000个。如果需要检查更多的数据，<pre class="language-none"><code class="language-none">$ src&#x2F;redis-migrate-tool -c rmt.conf -o log -C &quot;redis_check 200000&quot;Check job is running...Checked keys: 200000Inconsistent value keys: 0Inconsistent expire keys : 0Other check error keys: 0Checked OK keys: 200000All keys checked OK!Check job finished, used 11.962s</code></pre></li></ol><h3 id="rmt-conf配置文件"><a href="#rmt-conf配置文件" class="headerlink" title="rmt.conf配置文件"></a>rmt.conf配置文件</h3><p>配置文件包含三部分：[source], [target] 和 [common]</p><p>迁移工具的来源（source）可以是：单独的redis实例，twemproxy集群，redis cluster，rdb文件，aof文件。<br>迁移工具的目标（target）可以是：单独的redis实例，twemproxy集群，redis cluster，rdb文件。<br><pre class="language-none"><code class="language-none">[source]&#x2F;[target]：type：single：单独的redis实例twemproxy：twemproxy集群redis cluster：redis集群rdb file：.rdb文件aof file：.aof文件servers：redis地址组，如果type:twemproxy，则为twemproxy配置文件，如果type:rdb file，则为rdb文件名。redis_auth：连接redis服务的认证auth。timeout：读写redis服务的超时时间(ms)，默认为120000mshash：哈希方法名。仅当type:twemproxy有效。可以为one_at_a_time、md5、crc16、crc32、crc32a、fnv1_64、fnv1a_64、fnv1_32、fnv1a_32、hsieh、murmur、jenkins。hash_tag：用来哈希的关键key的两个字符，例如&quot;&#123;&#125;&quot; 或 &quot;$$&quot;。仅当type:twemproxy有效。只要标签内的关键key是相同的，能够将不同的键映射到同一服务器。distribution：键的分布模式。仅当type:twemproxy有效。可以为 ketama、modula、random。[common]：listen：监听的地址和端口。默认为127.0.0.1:8888max_clients：可监听端口的最大连接数。默认为100threads：工具可用的最多线程数。默认为cpu内核数。step：解析请求的步数。默认为1，数字越大，迁移越快，需要越多的内存。mbuf_size：请求的缓存大小（M），默认为512Mnoreply：是否检查目标组的回复，默认为falsesource_safe：是否保护源组机器的内存安全。默认为true，工具将允许在源组的同一台机器同时只有一个redis生成.rdb。dir：工作目录。用来存储文件，例如rdb文件，默认为当前目录。filter：过滤不符合表达式的Key，默认为NULL，支持通配符为glob-style风格? ：1个任意字符。例如 h?llo 匹配 hello, hallo , hxllo* ：0个或多个任意字符。例如 h*llo 匹配 hllo ， heeeello[characters]：匹配任意一个方括号内的字符，比如[abc]，要么匹配a，要么匹配b，要么匹配c。例如 h[ae]llo 匹配 hello ， hallo, 但不匹配 hillo。[^character]：排除方括号内的字符。例如h[^e]llo 匹配 hallo, hbllo, ... 但不匹配 hello。[character-character]：表示2个字符范围内的都可以匹配，如[a-z]，[0-9]。例如h[a-b]llo 匹配 hallo 和 hbllo。\用来转移特殊字符。</code></pre><br>更多例子见<br><a href="https://github.com/vipshop/redis-migrate-tool">https://github.com/vipshop/redis-migrate-tool</a></p><h3 id="监听redis-migrate-tool"><a href="#监听redis-migrate-tool" class="headerlink" title="监听redis-migrate-tool"></a>监听redis-migrate-tool</h3><p>可以使用redis-cli连接工具，监听地址和端口设置在配置文件的[common]下的listen，默认为127.0.0.1:8888</p><ol><li><p>info指令</p><pre class="language-none"><code class="language-none">$redis-cli -h 127.0.0.1 -p 8888127.0.0.1:8888&gt; info# Serverversion:0.1.0                                   # 工具的版本号os:Linux 2.6.32-573.12.1.el6.x86_64 x86_64      # 操作系统信息multiplexing_api:epoll                          # 多路复用接口gcc_version:4.4.7                               # gcc版本process_id:9199                                 # 工具的进程idtcp_port:8888                                   # 工具监听的tcp端口号uptime_in_seconds:1662                          # 工具运行的时间（秒）uptime_in_days:0                                # 工具运行的时间（天）config_file:&#x2F;ect&#x2F;rmt.conf                       # 工具运行的配置文件名称# Clientsconnected_clients:1                             # 当前连接的客户端数max_clients_limit:100                           # 客户端同时连接最大限制total_connections_received:3                    # 至今总共连接# Memorymem_allocator:jemalloc-4.0.4# Groupsource_nodes_count:32                          # 源redis组的节点数target_nodes_count:48                          # 目的redis组的节点数# Statsall_rdb_received:1                             # 是否已接收源redis组节点的所有.rdb文件all_rdb_parsed:1                               # 是否已解析源redis组节点的所有.rdb文件all_aof_loaded:0                               # 是否已加载源redis组节点的所有.aof文件rdb_received_count:32                          # 已接收的源redis组节点.rdb文件数rdb_parsed_count:32                            # 已解析的源redis组节点.rdb文件数aof_loaded_count:0                             # 已加载的源redis组节点.aof文件数total_msgs_recv:7753587                        # 从源组节点接收的所有消息数total_msgs_sent:7753587                        # 所有已发送目标节点并且收到的响应的消息数total_net_input_bytes:234636318                # 从源组接收的输入字节的总数total_net_output_bytes:255384129               # 已发送到目标组的输出字节的总数total_net_input_bytes_human:223.77M            # 同total_net_input_bytes，而是转换成人类可读的。total_net_output_bytes_human:243.55M           # 同total_net_output_bytes，而是转换成人类可读的。total_mbufs_inqueue:0                          # 来自源组的mbufs输入缓存的命令数据(不包括rdb数据)total_msgs_outqueue:0                          # 将被发送到目标组，和已被发送到目标，但正在等待响应的消息数</code></pre></li><li><p>shutdown [seconds|asap]</p></li></ol><p>执行指令后的行为：</p><p>停止从源redis复制<br>尝试将工具中的缓存数据发送到目标redis<br>Redis-migrate-tool 停止，退出<br>参数：</p><p>seconds：工具用于在退出之前将缓存的数据发送到目标redis的大多数时间。默认为10秒。<br>asap：不关心缓存的数据，立即退出。<br>例如，<br><pre class="language-none"><code class="language-none">$ redis-cli -h 127.0.0.1 -p 8888127.0.0.1:8888&gt; shutdown 5OK(5.00s)</code></pre></p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>不适用redis4.0.x及以上版本<br>当源中存在多库时，避免发生键值覆盖，最好换别的方式迁移<br>多源要不都不带密码，要不源是同一个密码，否则无法启动，在线变更密码可以通过config set requirepass [密码]</p>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;rmt介绍&quot;&gt;&lt;a href=&quot;#rmt介绍&quot; class=&quot;headerlink&quot; title=&quot;rmt介绍&quot;&gt;&lt;/a&gt;rmt介绍&lt;/h3&gt;&lt;p&gt;redis-migrate-tool 是维品会开源的一款redis数据迁移工具，基于redis复制，快速，稳定，github地址为：&lt;a href=&quot;https://github.com/vipshop/redis-migrate-tool&quot;&gt;https://github.com/vipshop/redis-migrate-tool&lt;/a&gt; 。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;快速。&lt;/li&gt;
&lt;li&gt;多线程。&lt;/li&gt;
&lt;li&gt;基于redis复制。&lt;/li&gt;
&lt;li&gt;实时迁移。&lt;/li&gt;
&lt;li&gt;迁移过程中，源集群不影响对外提供服务。&lt;/li&gt;
&lt;li&gt;异构迁移。&lt;/li&gt;
&lt;li&gt;支持Twemproxy集群，redis cluster集群，rdb文件 和 aof文件。&lt;/li&gt;
&lt;li&gt;过滤功能。&lt;/li&gt;
&lt;li&gt;当目标集群是Twemproxy，数据会跳过Twemproxy直接导入到后端的redis。&lt;/li&gt;
&lt;li&gt;迁移状态显示。&lt;/li&gt;
&lt;li&gt;完善的数据抽样校验(-C redis_check)。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;划重点 实时迁移 迁移过程中，源集群不影响对外提供服务&lt;br&gt;
    
    </summary>
    
      <category term="Redis" scheme="http://www.wiredtiger.org/categories/Redis/"/>
    
    
      <category term="redis" scheme="http://www.wiredtiger.org/tags/redis/"/>
    
  </entry>
  
  <entry>
    <title>redis性能分析工具redis-faina</title>
    <link href="http://www.wiredtiger.org/2019/07/07/2019-07-07-redis-faina/"/>
    <id>http://www.wiredtiger.org/2019/07/07/2019-07-07-redis-faina/</id>
    <published>2019-07-06T16:00:00.000Z</published>
    <updated>2020-04-16T11:09:53.062Z</updated>
    
    <content type="html"><![CDATA[<p>redis-faina是一个通过解析redis的MONITOR命令，从而对redis实例进行性能诊断的工具。<br>该工具使用虽然简单，但是功能还是很不错，对于定位线上redis性能问题，确实是一把利器。</p><h3 id="通过redis-MONITOR命令保存文件用于分析"><a href="#通过redis-MONITOR命令保存文件用于分析" class="headerlink" title="通过redis MONITOR命令保存文件用于分析"></a>通过redis MONITOR命令保存文件用于分析</h3><pre class="language-none"><code class="language-none">redis-cli -h 192.168.1.110 -p 6700 monitor |head -n 5000 &gt; redis-6700.txtredis-cli -h 192.168.1.111 -p 6701 monitor |head -n 5000 &gt; redis-6701.txt</code></pre><a id="more"></a><h3 id="redis-faina读取MONITOR日志进行分析："><a href="#redis-faina读取MONITOR日志进行分析：" class="headerlink" title="redis-faina读取MONITOR日志进行分析："></a>redis-faina读取MONITOR日志进行分析：</h3><pre class="language-none"><code class="language-none">.&#x2F;redis-faina.py ..&#x2F;redis_monitor_cmd&#x2F;redis-6701.txtOverall Stats&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;Lines Processed  5000   --- 总命令数Commands&#x2F;Sec     16348.00 --- QPSTop Prefixes  ---前缀最多的数据&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;dailyreward      873(17.46%)EXPEND_COIN_KEY  483(9.66%)exclusivereward  474(9.48%)user             465(9.30%)u                217(4.34%)redPackFeed      206(4.12%)vouchers         131(2.62%)newhandtask      122(2.44%)Top Keys ---使用最多的key&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;welfareRead                                    1566(31.32%)dailyreward:xx:xx  72  (1.44%)dailyreward:xx:xx  72  (1.44%)dailyreward:xx:xx  72  (1.44%)dailyreward:xx:xx  64  (1.28%)dailyreward:xx:xx   62  (1.24%)dailyreward:xx:xx  60  (1.20%)dailyreward:xx:xx   59  (1.18%)Top Commands ---使用的最多的命令&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;HGET      4035(80.70%)EXPIREAT  416 (8.32%)PING      137 (2.74%)HMGET     115 (2.30%)HINCRBY   61  (1.22%)LRANGE    39  (0.78%)EXPIRE    35  (0.70%)HSET      30  (0.60%)Command Time (microsecs) ---请求的响应时间分布&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;Median  39.075%     77.090%     136.2599%     326.0Heaviest Commands (microsecs) ---总体耗时最多的命令&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;HGET      245469.75EXPIREAT  25063.5PING      9035.25HMGET     8282.0HINCRBY   4135.25EXPIRE    2172.75LRANGE    2000.75HSET      1749.5Slowest Calls  --- 慢请求列表&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;620.0   &quot;HGET&quot; &quot;welfareRead&quot; &quot;3&quot;571.75  &quot;HGET&quot; &quot;welfareRead&quot; &quot;3&quot;531.5   &quot;HGET&quot; &quot;x&quot;494.75  &quot;HGET&quot; &quot;x&quot;489.0   &quot;EXPIREAT&quot; &quot;x&quot;477.0   &quot;HGET&quot; &quot;x&quot;471.0   &quot;HGET&quot; &quot;x&quot;470.25  &quot;HMGET&quot; &quot;x&quot;</code></pre><h3 id="notes"><a href="#notes" class="headerlink" title="notes:"></a>notes:</h3><p>大概能看出key的分布<br>由于redis MONITOR输出的只有请求开始的时间，所以在一个非常繁忙的redis实例中，根据该请求的开始时间以及下一个请求的开始时间，可以大概估算出一个请求的执行时间。由此可以看出，redis-faina统计的时间并不是十分精确的，尤其在分析一个非常闲的redis实例时，分析的结果可能差的很多。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;redis-faina是一个通过解析redis的MONITOR命令，从而对redis实例进行性能诊断的工具。&lt;br&gt;该工具使用虽然简单，但是功能还是很不错，对于定位线上redis性能问题，确实是一把利器。&lt;/p&gt;
&lt;h3 id=&quot;通过redis-MONITOR命令保存文件用于分析&quot;&gt;&lt;a href=&quot;#通过redis-MONITOR命令保存文件用于分析&quot; class=&quot;headerlink&quot; title=&quot;通过redis MONITOR命令保存文件用于分析&quot;&gt;&lt;/a&gt;通过redis MONITOR命令保存文件用于分析&lt;/h3&gt;&lt;pre class=&quot;language-none&quot;&gt;&lt;code class=&quot;language-none&quot;&gt;redis-cli -h 192.168.1.110 -p 6700 monitor |head -n 5000 &amp;gt; redis-6700.txt
redis-cli -h 192.168.1.111 -p 6701 monitor |head -n 5000 &amp;gt; redis-6701.txt&lt;/code&gt;&lt;/pre&gt;
    
    </summary>
    
      <category term="Redis" scheme="http://www.wiredtiger.org/categories/Redis/"/>
    
    
      <category term="redis key分布" scheme="http://www.wiredtiger.org/tags/redis-key%E5%88%86%E5%B8%83/"/>
    
  </entry>
  
  <entry>
    <title>CAT集群部署</title>
    <link href="http://www.wiredtiger.org/2019/05/15/2019-05-15-dianping-cat-install/"/>
    <id>http://www.wiredtiger.org/2019/05/15/2019-05-15-dianping-cat-install/</id>
    <published>2019-05-14T16:00:00.000Z</published>
    <updated>2019-06-17T08:46:12.486Z</updated>
    
    <content type="html"><![CDATA[<h3 id="cat集群机器列表"><a href="#cat集群机器列表" class="headerlink" title="cat集群机器列表"></a>cat集群机器列表</h3><p>cat1<br>192.168.1.110 8080<br>cat2<br>192.168.1.111 8080<br>cat3<br>192.168.1.112 8080</p><h3 id="部署tomcat"><a href="#部署tomcat" class="headerlink" title="部署tomcat"></a>部署tomcat</h3><p>新建setenv.sh然后添加环境变量<br><pre class="language-none"><code class="language-none">bin&#x2F;setenv.shexport CAT_HOME&#x3D;&#x2F;data&#x2F;apps&#x2F;data&#x2F;cat&#x2F;export JAVA_OPTS&#x3D;&quot;-server -Xms10g -Xmx10g -Xmn8g -XX:PermSize&#x3D;256m -XX:MaxPermSize&#x3D;512m -Dfile.encoding&#x3D;UTF-8 -verbose:gc -Xloggc:$&#123;CATALINA_HOME&#125;&#x2F;logs&#x2F;gc.log&#96;date +%Y-%m-%d-%H-%M&#96; -XX:+UseConcMarkSweepGC -XX:+CMSIncrementalMode -XX:+PrintGCDetails -XX:+PrintGCTimeStamps -noclassgc&quot;server.xml&lt;Connector port&#x3D;&quot;8080&quot; protocol&#x3D;&quot;HTTP&#x2F;1.1&quot;           URIEncoding&#x3D;&quot;utf-8&quot;    connectionTimeout&#x3D;&quot;20000&quot;               redirectPort&#x3D;&quot;8443&quot; &#x2F;&gt;  &lt;!-- 增加  URIEncoding&#x3D;&quot;utf-8&quot;  --&gt;  CAT_HOME目录权限chmod -R 777 $CAT_HOME</code></pre><br><a id="more"></a></p><h3 id="配置-data-appdatas-cat-client-xml-CAT-HOME-client-xml"><a href="#配置-data-appdatas-cat-client-xml-CAT-HOME-client-xml" class="headerlink" title="配置/data/appdatas/cat/client.xml ($CAT_HOME/client.xml)"></a>配置/data/appdatas/cat/client.xml ($CAT_HOME/client.xml)</h3><pre class="language-none"><code class="language-none">client.xml&lt;?xml version&#x3D;&quot;1.0&quot; encoding&#x3D;&quot;utf-8&quot;?&gt;&lt;config mode&#x3D;&quot;client&quot;&gt;    &lt;servers&gt;        &lt;server ip&#x3D;&quot;192.168.1.110&quot; port&#x3D;&quot;2280&quot; http-port&#x3D;&quot;8080&quot;&#x2F;&gt;        &lt;server ip&#x3D;&quot;192.168.1.111&quot; port&#x3D;&quot;2280&quot; http-port&#x3D;&quot;8080&quot;&#x2F;&gt;        &lt;server ip&#x3D;&quot;192.168.1.112&quot; port&#x3D;&quot;2280&quot; http-port&#x3D;&quot;8080&quot;&#x2F;&gt;    &lt;&#x2F;servers&gt;&lt;&#x2F;config&gt;</code></pre><h3 id="安装CAT数据库"><a href="#安装CAT数据库" class="headerlink" title="安装CAT数据库"></a>安装CAT数据库</h3><p>安装数据库并导入数据<br><pre class="language-none"><code class="language-none">mysql -uroot -Dcat &lt; CatApplication.sql</code></pre></p><h3 id="配置-data-appdatas-cat-datasources-xml-CAT-HOME-datasources-xml"><a href="#配置-data-appdatas-cat-datasources-xml-CAT-HOME-datasources-xml" class="headerlink" title="配置/data/appdatas/cat/datasources.xml($CAT_HOME/datasources.xml)"></a>配置/data/appdatas/cat/datasources.xml($CAT_HOME/datasources.xml)</h3><pre class="language-none"><code class="language-none">&lt;?xml version&#x3D;&quot;1.0&quot; encoding&#x3D;&quot;utf-8&quot;?&gt;&lt;data-sources&gt;&lt;data-source id&#x3D;&quot;cat&quot;&gt;&lt;maximum-pool-size&gt;3&lt;&#x2F;maximum-pool-size&gt;&lt;connection-timeout&gt;1s&lt;&#x2F;connection-timeout&gt;&lt;idle-timeout&gt;10m&lt;&#x2F;idle-timeout&gt;&lt;statement-cache-size&gt;1000&lt;&#x2F;statement-cache-size&gt;&lt;properties&gt;&lt;driver&gt;com.mysql.jdbc.Driver&lt;&#x2F;driver&gt;&lt;url&gt;&lt;![CDATA[jdbc:mysql:&#x2F;&#x2F;192.168.1.110:3306&#x2F;newsapp_cat]]&gt;&lt;&#x2F;url&gt;  &lt;!-- 请替换为真实数据库URL及Port  --&gt;&lt;user&gt;newsapp_cat&lt;&#x2F;user&gt;  &lt;!-- 请替换为真实数据库用户名  --&gt;&lt;password&gt;newsapp_cat_monitor&lt;&#x2F;password&gt;  &lt;!-- 请替换为真实数据库密码  --&gt;&lt;connectionProperties&gt;&lt;![CDATA[useUnicode&#x3D;true&amp;characterEncoding&#x3D;UTF-8&amp;autoReconnect&#x3D;true&amp;socketTimeout&#x3D;120000]]&gt;&lt;&#x2F;connectionProperties&gt;&lt;&#x2F;properties&gt;&lt;&#x2F;data-source&gt;&lt;&#x2F;data-sources&gt;</code></pre><h3 id="war打包"><a href="#war打包" class="headerlink" title="war打包"></a>war打包</h3><p><a href="http://unidal.org/nexus/service/local/repositories/releases/content/com/dianping/cat/cat-home/3.0.0/cat-home-3.0.0.war">官方下载</a></p><h3 id="war部署"><a href="#war部署" class="headerlink" title="war部署"></a>war部署</h3><p>cat.war部署到webapps目录下。<br>默认用户名：admin 默认密码：admin。</p><pre class="language-none"><code class="language-none">&lt;?xml version&#x3D;&quot;1.0&quot; encoding&#x3D;&quot;utf-8&quot;?&gt;&lt;router-config backup-server&#x3D;&quot;192.168.1.110&quot; backup-server-port&#x3D;&quot;2280&quot;&gt;   &lt;default-server id&#x3D;&quot;192.168.1.110&quot; weight&#x3D;&quot;1.0&quot; port&#x3D;&quot;2280&quot; enable&#x3D;&quot;false&quot;&#x2F;&gt;   &lt;default-server id&#x3D;&quot;192.168.1.111&quot; weight&#x3D;&quot;1.0&quot; port&#x3D;&quot;2280&quot; enable&#x3D;&quot;true&quot;&#x2F;&gt;   &lt;default-server id&#x3D;&quot;192.168.1.112&quot; weight&#x3D;&quot;1.0&quot; port&#x3D;&quot;2280&quot; enable&#x3D;&quot;true&quot;&#x2F;&gt;   &lt;network-policy id&#x3D;&quot;default&quot; title&#x3D;&quot;default&quot; block&#x3D;&quot;false&quot; server-group&#x3D;&quot;default_group&quot;&gt;   &lt;&#x2F;network-policy&gt;   &lt;server-group id&#x3D;&quot;default_group&quot; title&#x3D;&quot;default-group&quot;&gt;      &lt;group-server id&#x3D;&quot;192.168.1.111&quot;&#x2F;&gt;      &lt;group-server id&#x3D;&quot;192.168.1.112&quot;&#x2F;&gt;   &lt;&#x2F;server-group&gt;   &lt;domain id&#x3D;&quot;cat&quot;&gt;      &lt;group id&#x3D;&quot;default&quot;&gt;         &lt;server id&#x3D;&quot;192.168.1.111&quot; port&#x3D;&quot;2280&quot; weight&#x3D;&quot;1.0&quot;&#x2F;&gt;         &lt;server id&#x3D;&quot;192.168.1.112&quot; port&#x3D;&quot;2280&quot; weight&#x3D;&quot;1.0&quot;&#x2F;&gt;      &lt;&#x2F;group&gt;   &lt;&#x2F;domain&gt;&lt;&#x2F;router-config&gt;</code></pre><h3 id="服务端配置"><a href="#服务端配置" class="headerlink" title="服务端配置"></a>服务端配置</h3><p>配置链接：<a href="http://{ip:port}/cat/s/config?op=serverConfigUpdate">http://{ip:port}/cat/s/config?op=serverConfigUpdate</a><br><pre class="language-none"><code class="language-none">&lt;?xml version&#x3D;&quot;1.0&quot; encoding&#x3D;&quot;utf-8&quot;?&gt;&lt;server-config&gt;   &lt;server id&#x3D;&quot;default&quot;&gt;      &lt;properties&gt;         &lt;property name&#x3D;&quot;local-mode&quot; value&#x3D;&quot;false&quot;&#x2F;&gt;         &lt;property name&#x3D;&quot;job-machine&quot; value&#x3D;&quot;false&quot;&#x2F;&gt;         &lt;property name&#x3D;&quot;send-machine&quot; value&#x3D;&quot;false&quot;&#x2F;&gt;         &lt;property name&#x3D;&quot;alarm-machine&quot; value&#x3D;&quot;false&quot;&#x2F;&gt;         &lt;property name&#x3D;&quot;hdfs-enabled&quot; value&#x3D;&quot;false&quot;&#x2F;&gt;         &lt;property name&#x3D;&quot;remote-servers&quot; value&#x3D;&quot;192.168.1.110:8080,192.168.1.111:8080,192.168.1.112:8080&quot;&#x2F;&gt;      &lt;&#x2F;properties&gt;      &lt;storage local-base-dir&#x3D;&quot;&#x2F;data&#x2F;apps&#x2F;data&#x2F;cat&#x2F;bucket&#x2F;&quot; max-hdfs-storage-time&#x3D;&quot;15&quot; local-report-storage-time&#x3D;&quot;7&quot; local-logivew-storage-time&#x3D;&quot;7&quot; har-mode&#x3D;&quot;true&quot; upload-thread&#x3D;&quot;5&quot;&gt;         &lt;hdfs id&#x3D;&quot;logview&quot; max-size&#x3D;&quot;128M&quot; server-uri&#x3D;&quot;hdfs:&#x2F;&#x2F;10.1.77.86&#x2F;&quot; base-dir&#x3D;&quot;user&#x2F;cat&#x2F;logview&quot;&#x2F;&gt;         &lt;hdfs id&#x3D;&quot;dump&quot; max-size&#x3D;&quot;128M&quot; server-uri&#x3D;&quot;hdfs:&#x2F;&#x2F;10.1.77.86&#x2F;&quot; base-dir&#x3D;&quot;user&#x2F;cat&#x2F;dump&quot;&#x2F;&gt;         &lt;hdfs id&#x3D;&quot;remote&quot; max-size&#x3D;&quot;128M&quot; server-uri&#x3D;&quot;hdfs:&#x2F;&#x2F;10.1.77.86&#x2F;&quot; base-dir&#x3D;&quot;user&#x2F;cat&#x2F;remote&quot;&#x2F;&gt;      &lt;&#x2F;storage&gt;      &lt;consumer&gt;         &lt;long-config default-url-threshold&#x3D;&quot;1000&quot; default-sql-threshold&#x3D;&quot;100&quot; default-service-threshold&#x3D;&quot;50&quot;&gt;            &lt;domain name&#x3D;&quot;cat&quot; url-threshold&#x3D;&quot;500&quot; sql-threshold&#x3D;&quot;500&quot;&#x2F;&gt;            &lt;domain name&#x3D;&quot;OpenPlatformWeb&quot; url-threshold&#x3D;&quot;100&quot; sql-threshold&#x3D;&quot;500&quot;&#x2F;&gt;         &lt;&#x2F;long-config&gt;      &lt;&#x2F;consumer&gt;   &lt;&#x2F;server&gt;   &lt;server id&#x3D;&quot;192.168.1.110&quot;&gt;      &lt;properties&gt;         &lt;property name&#x3D;&quot;job-machine&quot; value&#x3D;&quot;true&quot;&#x2F;&gt;         &lt;property name&#x3D;&quot;alarm-machine&quot; value&#x3D;&quot;true&quot;&#x2F;&gt;         &lt;property name&#x3D;&quot;send-machine&quot; value&#x3D;&quot;true&quot;&#x2F;&gt;      &lt;&#x2F;properties&gt;   &lt;&#x2F;server&gt;&lt;&#x2F;server-config&gt;</code></pre></p><h3 id="notes"><a href="#notes" class="headerlink" title="notes:"></a>notes:</h3><p><a href="https://github.com/dianping/cat/wiki/readme_server">https://github.com/dianping/cat/wiki/readme_server</a></p>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;cat集群机器列表&quot;&gt;&lt;a href=&quot;#cat集群机器列表&quot; class=&quot;headerlink&quot; title=&quot;cat集群机器列表&quot;&gt;&lt;/a&gt;cat集群机器列表&lt;/h3&gt;&lt;p&gt;cat1&lt;br&gt;192.168.1.110 8080&lt;br&gt;cat2&lt;br&gt;192.168.1.111 8080&lt;br&gt;cat3&lt;br&gt;192.168.1.112 8080&lt;/p&gt;
&lt;h3 id=&quot;部署tomcat&quot;&gt;&lt;a href=&quot;#部署tomcat&quot; class=&quot;headerlink&quot; title=&quot;部署tomcat&quot;&gt;&lt;/a&gt;部署tomcat&lt;/h3&gt;&lt;p&gt;新建setenv.sh然后添加环境变量&lt;br&gt;&lt;pre class=&quot;language-none&quot;&gt;&lt;code class=&quot;language-none&quot;&gt;bin&amp;#x2F;setenv.sh
export CAT_HOME&amp;#x3D;&amp;#x2F;data&amp;#x2F;apps&amp;#x2F;data&amp;#x2F;cat&amp;#x2F;
export JAVA_OPTS&amp;#x3D;&amp;quot;-server -Xms10g -Xmx10g -Xmn8g -XX:PermSize&amp;#x3D;256m -XX:MaxPermSize&amp;#x3D;512m -Dfile.encoding&amp;#x3D;UTF-8 -verbose:gc -Xloggc:$&amp;#123;CATALINA_HOME&amp;#125;&amp;#x2F;logs&amp;#x2F;gc.log&amp;#96;date +%Y-%m-%d-%H-%M&amp;#96; -XX:+UseConcMarkSweepGC -XX:+CMSIncrementalMode -XX:+PrintGCDetails -XX:+PrintGCTimeStamps -noclassgc&amp;quot;

server.xml
&amp;lt;Connector port&amp;#x3D;&amp;quot;8080&amp;quot; protocol&amp;#x3D;&amp;quot;HTTP&amp;#x2F;1.1&amp;quot;
           URIEncoding&amp;#x3D;&amp;quot;utf-8&amp;quot;    connectionTimeout&amp;#x3D;&amp;quot;20000&amp;quot;
               redirectPort&amp;#x3D;&amp;quot;8443&amp;quot; &amp;#x2F;&amp;gt;  &amp;lt;!-- 增加  URIEncoding&amp;#x3D;&amp;quot;utf-8&amp;quot;  --&amp;gt;  

CAT_HOME目录权限
chmod -R 777 $CAT_HOME
&lt;/code&gt;&lt;/pre&gt;&lt;br&gt;
    
    </summary>
    
      <category term="Linux" scheme="http://www.wiredtiger.org/categories/Linux/"/>
    
    
      <category term="cat" scheme="http://www.wiredtiger.org/tags/cat/"/>
    
  </entry>
  
  <entry>
    <title>elastic 迁移</title>
    <link href="http://www.wiredtiger.org/2019/04/22/2019-04-22-elasticsearch-migration-notes/"/>
    <id>http://www.wiredtiger.org/2019/04/22/2019-04-22-elasticsearch-migration-notes/</id>
    <published>2019-04-21T16:00:00.000Z</published>
    <updated>2020-11-20T10:46:46.621Z</updated>
    
    <content type="html"><![CDATA[<h3 id="es迁移测试工具对比"><a href="#es迁移测试工具对比" class="headerlink" title="es迁移测试工具对比"></a>es迁移测试工具对比</h3><table><thead><tr><th>测试工具</th><th>是否成功</th><th>环境搭建</th><th>迁移版本是否支持</th><th>工具地址</th></tr></thead><tbody><tr><td>Elasticsearch Migration</td><td>是</td><td>简单，二进制下载即可用</td><td>5.0-&gt;5.0</td><td><a href="https://github.com/medcl/esm-abandoned">https://github.com/medcl/esm-abandoned</a></td></tr><tr><td>logstash迁移</td><td>是</td><td>更新和es对应版本</td><td>支持跨版本,logstash5.0</td><td></td></tr><tr><td>Elasticsearch-Exporter</td><td>否</td><td>node环境依赖，复杂</td><td><a href="https://github.com/mallocator/Elasticsearch-Exporter">https://github.com/mallocator/Elasticsearch-Exporter</a></td></tr></tbody></table><p>小结：对比选择使用esm，logstash辅助。</p><a id="more"></a><p>esm迁移脚本<br><pre class="language-none"><code class="language-none">#!&#x2F;bin&#x2F;sh dir&#x3D;&quot;&#x2F;data&#x2F;apps&#x2F;opt&quot;cd $diresindex&#x3D;&#96;curl -s &#39;http:&#x2F;&#x2F;127.0.0.1:9200&#x2F;_cat&#x2F;indices&#39; | grep -e logstash-09* | awk &#39;&#123;print $3&#125;&#39;&#96;#echo $esindex for i in $esindex;do.&#x2F;esm  -s http:&#x2F;&#x2F;127.0.0.1:9200 -x $i  -d http:&#x2F;&#x2F;192.168.1.100:9200 -x $i  -w&#x3D;5 -b&#x3D;10 -c 10000done</code></pre></p><p>es保留30的数据<br><pre class="language-none"><code class="language-none">#!&#x2F;bin&#x2F;bashDATE&#x3D;&#96;date +%Y.%m.%d.%I&#96;DATA1&#x3D;&#96;date +%Y.%m.%d -d&#39;-30 day&#39;&#96;DATA2&#x3D;&#96;date +%Y.%m.%d -d&#39;-30 day&#39;&#96;#关闭索引curl -XPOST &quot;http:&#x2F;&#x2F;localhost:9200&#x2F;logstash*$&#123;DATA1&#125;*&#x2F;_close?pretty&quot;#删除索引curl -XDELETE &quot;http:&#x2F;&#x2F;localhost:9200&#x2F;logstash*$&#123;DATA2&#125;*?pretty</code></pre></p>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;es迁移测试工具对比&quot;&gt;&lt;a href=&quot;#es迁移测试工具对比&quot; class=&quot;headerlink&quot; title=&quot;es迁移测试工具对比&quot;&gt;&lt;/a&gt;es迁移测试工具对比&lt;/h3&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;测试工具&lt;/th&gt;
&lt;th&gt;是否成功&lt;/th&gt;
&lt;th&gt;环境搭建&lt;/th&gt;
&lt;th&gt;迁移版本是否支持&lt;/th&gt;
&lt;th&gt;工具地址&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Elasticsearch Migration&lt;/td&gt;
&lt;td&gt;是&lt;/td&gt;
&lt;td&gt;简单，二进制下载即可用&lt;/td&gt;
&lt;td&gt;5.0-&amp;gt;5.0&lt;/td&gt;
&lt;td&gt;&lt;a href=&quot;https://github.com/medcl/esm-abandoned&quot;&gt;https://github.com/medcl/esm-abandoned&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;logstash迁移&lt;/td&gt;
&lt;td&gt;是&lt;/td&gt;
&lt;td&gt;更新和es对应版本&lt;/td&gt;
&lt;td&gt;支持跨版本,logstash5.0&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Elasticsearch-Exporter&lt;/td&gt;
&lt;td&gt;否&lt;/td&gt;
&lt;td&gt;node环境依赖，复杂&lt;/td&gt;
&lt;td&gt;&lt;a href=&quot;https://github.com/mallocator/Elasticsearch-Exporter&quot;&gt;https://github.com/mallocator/Elasticsearch-Exporter&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;小结：对比选择使用esm，logstash辅助。&lt;/p&gt;
    
    </summary>
    
      <category term="ELK" scheme="http://www.wiredtiger.org/categories/ELK/"/>
    
    
      <category term="elk" scheme="http://www.wiredtiger.org/tags/elk/"/>
    
  </entry>
  
  <entry>
    <title>Redis 迁移工具</title>
    <link href="http://www.wiredtiger.org/2019/03/21/2019-03-21-redis-migrate-tool/"/>
    <id>http://www.wiredtiger.org/2019/03/21/2019-03-21-redis-migrate-tool/</id>
    <published>2019-03-20T16:00:00.000Z</published>
    <updated>2020-04-10T04:13:43.605Z</updated>
    
    <content type="html"><![CDATA[<h3 id="rmt安装"><a href="#rmt安装" class="headerlink" title="rmt安装"></a>rmt安装</h3><p>Redis-Migrate-Tool集群迁移工具，基于redis复制，快速，稳定。</p><p><a href="https://github.com/vipshop/redis-migrate-tool">github地址</a></p><pre class="language-none"><code class="language-none">cd redis-migrate-toolautoreconf -fvi.&#x2F;configuremakesrc&#x2F;redis-migrate-tool -h</code></pre><a id="more"></a><h3 id="迁移"><a href="#迁移" class="headerlink" title="迁移"></a>迁移</h3><p>单实例迁移到单实例<br><pre class="language-none"><code class="language-none">执行迁移src&#x2F;redis-migrate-tool -c single2single.conf -o single2single.log -dsingle2single.conf[source]type: singleservers: - 192.168.1.100:6379redis_auth: 123456[target]type: singleservers: - 192.168.1.111:6379redis_auth: abcdef[common]listen: 0.0.0.0:8888threads: 4step: 2mbuf_size: 1024source_safe: true</code></pre></p><p>单实例迁移到集群<br><pre class="language-none"><code class="language-none">执行迁移src&#x2F;redis-migrate-tool -c single2cluster.conf -o single2cluster.log -dsingle2cluster.conf[source]type: singleservers: - 192.168.1.100:6379redis_auth: 123456[target]type: redis clusterservers: - 192.168.1.111:6379redis_auth: abcdef[common]listen: 0.0.0.0:9999threads: 4step: 2mbuf_size: 1024source_safe: true</code></pre></p><h3 id="RedisShake"><a href="#RedisShake" class="headerlink" title="RedisShake"></a>RedisShake</h3><p>redis-shake是阿里云Redis&amp;MongoDB团队开源的用于redis数据同步的工具。<a href="https://github.com/alibaba/RedisShake/releases">RedisShake地址</a></p><p>下载解压即可食用</p><p>集群版cluster到集群版cluster配置举例<br><pre class="language-none"><code class="language-none">source.type: clustersource.address: 10.1.1.1:20441;10.1.1.1:20443;10.1.1.1:20445source.password_raw: 12345target.type: clustertarget.address: 10.1.1.1:20551;10.1.1.1:20553;10.1.1.1:20555target.password_raw: 12345</code></pre></p><p>对于source.address或者target.address，需要配置源端的所有集群中db节点列表以及目的端集群所有db节点列表，用户也可以启用自动发现机制，地址以’@’开头，redis-shake将会根据cluster nodes命令自动去探测有几个节点。对于source.address，用户可以在’@’前面配置master（默认）或者slave表示分表从master或者slave进行拉取；对于target.address，只能是master或者不配置：<br><pre class="language-none"><code class="language-none">source.address: master@10.1.1.1:20441 # 将会自动探测到10.1.1.1:20441集群下的所有节点，并从所有master进行拉取。target.address: @10.1.1.1:20551 # 将会自动探测到10.1.1.1:20551集群下的所有节点，并写入所有master。</code></pre><br>可以手动写所有节点，也可以@写一个自动探测。</p><h3 id="启动停止"><a href="#启动停止" class="headerlink" title="启动停止"></a>启动停止</h3><pre class="language-none"><code class="language-none">&#x2F;data&#x2F;apps&#x2F;opt&#x2F;redis-shake&#x2F;start.sh redis-shake.conf rsync&#x2F;stop.sh redis-shake.pid</code></pre><h3 id="redis-shake-迁移监控"><a href="#redis-shake-迁移监控" class="headerlink" title="redis-shake 迁移监控"></a>redis-shake 迁移监控</h3><p>用户可以通过我们提供的restful拉取metric来对redis-shake进行实时监控：curl 127.0.0.1:9320/metric</p><p>校验使用redis-migrate-tool 随机校验或者使用show_redis_map.sh脚本看下大概key总量。</p><h3 id="迁移校验"><a href="#迁移校验" class="headerlink" title="迁移校验"></a>迁移校验</h3><p>src/redis-migrate-tool -c single2single.conf -o log -C redis_check<br>src/redis-migrate-tool -c single2single.conf -o log -C “redis_check 200000”</p><h3 id="notes"><a href="#notes" class="headerlink" title="notes"></a>notes</h3><p><a href="https://github.com/vipshop/redis-migrate-tool">https://github.com/vipshop/redis-migrate-tool</a><br><a href="https://github.com/alibaba/RedisShake">https://github.com/alibaba/RedisShake</a></p>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;rmt安装&quot;&gt;&lt;a href=&quot;#rmt安装&quot; class=&quot;headerlink&quot; title=&quot;rmt安装&quot;&gt;&lt;/a&gt;rmt安装&lt;/h3&gt;&lt;p&gt;Redis-Migrate-Tool集群迁移工具，基于redis复制，快速，稳定。&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://github.com/vipshop/redis-migrate-tool&quot;&gt;github地址&lt;/a&gt;&lt;/p&gt;
&lt;pre class=&quot;language-none&quot;&gt;&lt;code class=&quot;language-none&quot;&gt;cd redis-migrate-tool
autoreconf -fvi
.&amp;#x2F;configure
make
src&amp;#x2F;redis-migrate-tool -h&lt;/code&gt;&lt;/pre&gt;
    
    </summary>
    
      <category term="Redis" scheme="http://www.wiredtiger.org/categories/Redis/"/>
    
    
      <category term="rmt RedisShake" scheme="http://www.wiredtiger.org/tags/rmt-RedisShake/"/>
    
  </entry>
  
  <entry>
    <title>Redis Cluster集群搭建</title>
    <link href="http://www.wiredtiger.org/2019/01/15/2019-01-15-redis-cluster-install/"/>
    <id>http://www.wiredtiger.org/2019/01/15/2019-01-15-redis-cluster-install/</id>
    <published>2019-01-14T16:00:00.000Z</published>
    <updated>2019-06-17T07:51:31.610Z</updated>
    
    <content type="html"><![CDATA[<h3 id="redis-cluster集群构建"><a href="#redis-cluster集群构建" class="headerlink" title="redis cluster集群构建"></a>redis cluster集群构建</h3><p>10.16.76.144 6000<br>10.16.76.144 6001<br>10.16.76.144 6002</p><p>集群密码：abcdefg</p><h3 id="配置主节点"><a href="#配置主节点" class="headerlink" title="配置主节点"></a>配置主节点</h3><pre class="language-none"><code class="language-none">10.16.76.144 6000cluster meet 10.16.76.144 6001cluster meet 10.16.76.144 6002cluster nodescluster info</code></pre><h3 id="分配槽位"><a href="#分配槽位" class="headerlink" title="分配槽位"></a>分配槽位</h3><p>node1分配：0~5461<br>node2分配：5462~10922<br>node3分配：10923~16383</p><a id="more"></a><p>分配脚本addslots.sh<br><pre class="language-none"><code class="language-none">#!&#x2F;bin&#x2F;bashREDIS_CLI&#x3D;&#96;which redis-cli&#96;REDIS_PASS&#x3D;&#39;&#39;#node1n&#x3D;0for ((i&#x3D;n;i&lt;&#x3D;5461;i++))do   $REDIS-CLI -h 10.16.76.144 -p 6000 -a $REDIS_PASS CLUSTER ADDSLOTS $idone#node2n&#x3D;5462for ((i&#x3D;n;i&lt;&#x3D;10922;i++))do   $REDIS-CLI -h 10.16.76.144 -p 6001 -a $REDIS_PASS CLUSTER ADDSLOTS $idone#node3#!&#x2F;bin&#x2F;bashn&#x3D;10923for ((i&#x3D;n;i&lt;&#x3D;16383;i++))do   $REDIS-CLI -h 10.16.76.144 -p 6002 -a $REDIS_PASS CLUSTER ADDSLOTS $idone</code></pre></p><h3 id="redis集群动态添加密码"><a href="#redis集群动态添加密码" class="headerlink" title="redis集群动态添加密码"></a>redis集群动态添加密码</h3><pre class="language-none"><code class="language-none">config rewrite 写入配置for i in &#123;6000..6002&#125;; do echo $i;donefor i in &#123;6000..6002&#125;;  do echo $i; redis-cli -c -h 10.16.76.144 -p $i config set requirepass abcdefg ;done</code></pre><h3 id="redis-cluster常用命令"><a href="#redis-cluster常用命令" class="headerlink" title="redis cluster常用命令"></a>redis cluster常用命令</h3><pre class="language-none"><code class="language-none">查看key所在slotcluster keyslot key_name</code></pre>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;redis-cluster集群构建&quot;&gt;&lt;a href=&quot;#redis-cluster集群构建&quot; class=&quot;headerlink&quot; title=&quot;redis cluster集群构建&quot;&gt;&lt;/a&gt;redis cluster集群构建&lt;/h3&gt;&lt;p&gt;10.16.76.144 6000&lt;br&gt;10.16.76.144 6001&lt;br&gt;10.16.76.144 6002&lt;/p&gt;
&lt;p&gt;集群密码：abcdefg&lt;/p&gt;
&lt;h3 id=&quot;配置主节点&quot;&gt;&lt;a href=&quot;#配置主节点&quot; class=&quot;headerlink&quot; title=&quot;配置主节点&quot;&gt;&lt;/a&gt;配置主节点&lt;/h3&gt;&lt;pre class=&quot;language-none&quot;&gt;&lt;code class=&quot;language-none&quot;&gt;10.16.76.144 6000
cluster meet 10.16.76.144 6001
cluster meet 10.16.76.144 6002

cluster nodes
cluster info
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&quot;分配槽位&quot;&gt;&lt;a href=&quot;#分配槽位&quot; class=&quot;headerlink&quot; title=&quot;分配槽位&quot;&gt;&lt;/a&gt;分配槽位&lt;/h3&gt;&lt;p&gt;node1分配：0~5461&lt;br&gt;node2分配：5462~10922&lt;br&gt;node3分配：10923~16383&lt;/p&gt;
    
    </summary>
    
      <category term="Redis" scheme="http://www.wiredtiger.org/categories/Redis/"/>
    
    
      <category term="Redis" scheme="http://www.wiredtiger.org/tags/Redis/"/>
    
  </entry>
  
  <entry>
    <title>K8S常用命令</title>
    <link href="http://www.wiredtiger.org/2018/12/08/2018-08-15-k8s-common-use/"/>
    <id>http://www.wiredtiger.org/2018/12/08/2018-08-15-k8s-common-use/</id>
    <published>2018-12-07T16:00:00.000Z</published>
    <updated>2020-08-26T07:44:08.235Z</updated>
    
    <content type="html"><![CDATA[<pre class="language-none"><code class="language-none">获取集群状态kubectl get componentstatus kubectl get cs获取node节点kubectl get nodes获取node节点ipkubectl get node -o json |grep  &quot;address&quot; |grep -v &#39;addresses&#39; |awk  &#39;&#123; print $2&#125;&#39; |sort -nr |uniq |cut -d&#39;&quot;&#39; -f2kubectl scale sts myapp --replication&#x3D;5kubectl patch sts myapp --repli更新指定容器镜像版本kubectl set image deployment&#x2F;myapp busybox&#x3D;busybox:v2回滚kubectl rollout undo deployment&#x2F;myapp扩容kubectl scale --replicas&#x3D;3 deployment myapp缩容kubectl scale --replicas&#x3D;3 deployment myapp观察更新状态kubectl rollout status deployment myapp查看历史版本kubectl rollout history deployment myapp查看节点的 label。kubectl get nodes --show-labels增加labelkubectl label node k8s-node1 app&#x3D;zkkubectl label pod myapp-01 app&#x3D;myappkubectl get pod -Lapp删除 label app，执行如下命令：kubectl label node k8s-node1 app-- 即删除。根据标签查询节点kubectl get node -a -l &quot;node&#x3D;kube-node&quot;kubectl label nodes 10.126.72.31 points&#x3D;test会给10.126.72.31这个节点添加一个标签：points&#x3D;test</code></pre>]]></content>
    
    <summary type="html">
    
      
      
        &lt;pre class=&quot;language-none&quot;&gt;&lt;code class=&quot;language-none&quot;&gt;获取集群状态
kubectl get componentstatus 
kubectl get cs

获取node节点
kubectl get nodes

获取nod
      
    
    </summary>
    
      <category term="K8S" scheme="http://www.wiredtiger.org/categories/K8S/"/>
    
    
      <category term="kubernetes" scheme="http://www.wiredtiger.org/tags/kubernetes/"/>
    
  </entry>
  
  <entry>
    <title>Nexus OSS私服的安装和迁移</title>
    <link href="http://www.wiredtiger.org/2018/10/18/2018-10-18-nexus-oss-install/"/>
    <id>http://www.wiredtiger.org/2018/10/18/2018-10-18-nexus-oss-install/</id>
    <published>2018-10-17T16:00:00.000Z</published>
    <updated>2019-04-29T12:35:16.483Z</updated>
    
    <content type="html"><![CDATA[<h3 id="Nexus私服"><a href="#Nexus私服" class="headerlink" title="Nexus私服"></a>Nexus私服</h3><p>Nexus常用功能就是：指定私服的中央地址、将自己的Maven项目指定到私服地址、从私服下载中央库的项目索引、从私服仓库下载依赖组件、将第三方项目jar上传到私服供其他项目组使用。</p><p>一般用到的仓库种类是hosted、proxy。 </p><ol><li>Hosted代表宿主仓库，用来发布一些第三方不允许的组件，比如Oracle驱动、比如商业软件jar包。</li><li>Proxy代表代理远程的仓库，最典型的就是Maven官方中央仓库、JBoss仓库等等。如果构建的Maven项目本地仓库没有依赖包，<br>那么就会去这个代理站点去下载，那么如果代理站点也没有此依赖包，就回去远程中央仓库下载依赖，这些中央仓库就是proxy。代理站点下载成功后再下载至本机。</li></ol><a id="more"></a><h3 id="下载解压nexus"><a href="#下载解压nexus" class="headerlink" title="下载解压nexus"></a>下载解压nexus</h3><p>Nexus Repository Manager OSS ,之前叫做 Nexus OS，是开源免费的。【OSS = Open Source Software，开源软件——免费】</p><p>Nexus Repository Manager，之前叫做 Nexus Professional。只有拥有一个有效的许可证才可以使用所有功能【专业版本——收费</p><pre class="language-none"><code class="language-none">wget https:&#x2F;&#x2F;download.sonatype.com&#x2F;nexus&#x2F;oss&#x2F;nexus-latest-bundle.tar.gztar zxvf nexus-latest-bundle.tar.gz  -C &#x2F;data&#x2F;app&#x2F;optcp bin&#x2F;nexus &#x2F;etc&#x2F;init.d&#x2F;nexus2 设置nexus服务开机自启动chkconfig --add nexus2chkconfig nexus2 on &#x2F;etc&#x2F;init.d&#x2F;nexus2 start默认admin&#x2F;admin123</code></pre><h3 id="Nexus2配置文件"><a href="#Nexus2配置文件" class="headerlink" title="Nexus2配置文件"></a>Nexus2配置文件</h3><pre class="language-none"><code class="language-none">&#x2F;etc&#x2F;init.d&#x2F;nexus2 修改NEXUS_HOME修改为Nexus的解压目录 &#x2F;data&#x2F;apps&#x2F;opt&#x2F;nexus-2.14.11-01RUN_AS_USER修改为 rootcd &#x2F;data&#x2F;apps&#x2F;opt&#x2F;nexus-2.14.11-01bin&#x2F;jsw&#x2F;conf&#x2F;wrapper.conf 修改#设置好Java执行文件所处的位置wrapper.java.command&#x3D;&#x2F;usr&#x2F;java&#x2F;bin&#x2F;javaNexus2监听的端口以及仓库存储位置conf&#x2F;nexus.properties# Jetty sectionapplication-port&#x3D;8081  #端口application-host&#x3D;0.0.0.0nexus-webapp&#x3D;$&#123;bundleBasedir&#125;&#x2F;nexusnexus-webapp-context-path&#x3D;&#x2F;nexus# Nexus section#nexus-work&#x3D;$&#123;bundleBasedir&#125;&#x2F;..&#x2F;sonatype-work&#x2F;nexusnexus-work&#x3D;&#x2F;data&#x2F;apps&#x2F;data&#x2F;sonatype-work&#x2F;nexus #仓库存储位置runtime&#x3D;$&#123;bundleBasedir&#125;&#x2F;nexus&#x2F;WEB-INF# orientdb buffer size in megabytesstorage.diskCache.bufferSize&#x3D;4096</code></pre><h3 id="仓库的备份与迁移"><a href="#仓库的备份与迁移" class="headerlink" title="仓库的备份与迁移"></a>仓库的备份与迁移</h3><p>登陆旧的Nexus OSS私服仓库，查看conf/nexus.properties 配置，找到仓库存储位置<br>同步数据目录到新的Nexus OSS私服仓库<br>重启nexus即可</p>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;Nexus私服&quot;&gt;&lt;a href=&quot;#Nexus私服&quot; class=&quot;headerlink&quot; title=&quot;Nexus私服&quot;&gt;&lt;/a&gt;Nexus私服&lt;/h3&gt;&lt;p&gt;Nexus常用功能就是：指定私服的中央地址、将自己的Maven项目指定到私服地址、从私服下载中央库的项目索引、从私服仓库下载依赖组件、将第三方项目jar上传到私服供其他项目组使用。&lt;/p&gt;
&lt;p&gt;一般用到的仓库种类是hosted、proxy。 &lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Hosted代表宿主仓库，用来发布一些第三方不允许的组件，比如Oracle驱动、比如商业软件jar包。&lt;/li&gt;
&lt;li&gt;Proxy代表代理远程的仓库，最典型的就是Maven官方中央仓库、JBoss仓库等等。如果构建的Maven项目本地仓库没有依赖包，&lt;br&gt;那么就会去这个代理站点去下载，那么如果代理站点也没有此依赖包，就回去远程中央仓库下载依赖，这些中央仓库就是proxy。代理站点下载成功后再下载至本机。&lt;/li&gt;
&lt;/ol&gt;
    
    </summary>
    
      <category term="Linux" scheme="http://www.wiredtiger.org/categories/Linux/"/>
    
    
      <category term="Nexus" scheme="http://www.wiredtiger.org/tags/Nexus/"/>
    
  </entry>
  
  <entry>
    <title>YUM源制作</title>
    <link href="http://www.wiredtiger.org/2018/07/09/2018-07-09-yum-repo-make/"/>
    <id>http://www.wiredtiger.org/2018/07/09/2018-07-09-yum-repo-make/</id>
    <published>2018-07-08T16:00:00.000Z</published>
    <updated>2019-07-08T02:04:27.417Z</updated>
    
    <content type="html"><![CDATA[<h3 id="安装createrepo"><a href="#安装createrepo" class="headerlink" title="安装createrepo"></a>安装createrepo</h3><pre class="language-none"><code class="language-none">yum install createrepo创建本地仓库createrepo &#x2F;data&#x2F;repo&#x2F;RPMS添加rpm包，更新本地仓库createrepo --update &#x2F;data&#x2F;repo&#x2F;RPMS此命令只能下载主机未安装的包yum install 包名 --downloadonly --downloaddir&#x3D;&#x2F;data&#x2F;repo如果本机器已经安装，下载相关包yum reinstall 包名 --downloadonly --downloaddir&#x3D;&#x2F;data&#x2F;repo指定仓库安装yum  --disablerepo&#x3D;openstack-kilo,openstack-liberty,openstack-mitaka,7ASU3-updates  --enablerepo&#x3D;appserver  localinstall -y —nogpgcheck monit </code></pre><a id="more"></a><h3 id="nginx配置"><a href="#nginx配置" class="headerlink" title="nginx配置"></a>nginx配置</h3><pre class="language-none"><code class="language-none">cat repo.confserver &#123;    listen       8080;    server_name  0.0.0.0;    access_log  logs&#x2F;repo.access.log  main;    root &#x2F;data&#x2F;repo&#x2F;RPMS;    autoindex on;    location &#x2F; &#123;    &#125;    error_page   500 502 503 504  &#x2F;50x.html;    location &#x3D; &#x2F;50x.html &#123;        root   html;    &#125;&#125;</code></pre><h3 id="使用自建repo源"><a href="#使用自建repo源" class="headerlink" title="使用自建repo源"></a>使用自建repo源</h3><pre class="language-none"><code class="language-none"> cat &#x2F;etc&#x2F;yum.repos.d&#x2F;appserver.repo[appserver]name&#x3D;Extra Packages for appserver - $basearchbaseurl&#x3D;http:&#x2F;&#x2F;10.16.76.135:8080gpgcheck&#x3D;0enabled&#x3D;1</code></pre>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;安装createrepo&quot;&gt;&lt;a href=&quot;#安装createrepo&quot; class=&quot;headerlink&quot; title=&quot;安装createrepo&quot;&gt;&lt;/a&gt;安装createrepo&lt;/h3&gt;&lt;pre class=&quot;language-none&quot;&gt;&lt;code class=&quot;language-none&quot;&gt;yum install createrepo

创建本地仓库
createrepo &amp;#x2F;data&amp;#x2F;repo&amp;#x2F;RPMS
添加rpm包，更新本地仓库
createrepo --update &amp;#x2F;data&amp;#x2F;repo&amp;#x2F;RPMS

此命令只能下载主机未安装的包
yum install 包名 --downloadonly --downloaddir&amp;#x3D;&amp;#x2F;data&amp;#x2F;repo

如果本机器已经安装，下载相关包
yum reinstall 包名 --downloadonly --downloaddir&amp;#x3D;&amp;#x2F;data&amp;#x2F;repo

指定仓库安装
yum  --disablerepo&amp;#x3D;openstack-kilo,openstack-liberty,openstack-mitaka,7ASU3-updates  --enablerepo&amp;#x3D;appserver  localinstall -y —nogpgcheck monit &lt;/code&gt;&lt;/pre&gt;
    
    </summary>
    
      <category term="Linux" scheme="http://www.wiredtiger.org/categories/Linux/"/>
    
    
      <category term="yum" scheme="http://www.wiredtiger.org/tags/yum/"/>
    
  </entry>
  
</feed>
